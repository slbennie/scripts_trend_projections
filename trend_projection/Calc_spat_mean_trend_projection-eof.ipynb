{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1addd5f-6e2a-43fa-82f8-b155037c3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import linregress\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe5a59a-c91a-4956-9ee3-e202c8f4e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the correct calendar (model dependent.)\n",
    "def get_time_bounds(calendar_type, start, end):\n",
    "    #1850-2015 all of 2014 - none of 2015.\n",
    "    if calendar_type == cftime.DatetimeNoLeap:\n",
    "        return cftime.DatetimeNoLeap(start,1,16), cftime.DatetimeNoLeap(end,1,16)\n",
    "    elif calendar_type == cftime.Datetime360Day:\n",
    "        return cftime.Datetime360Day(start,1,16), cftime.Datetime360Day(end-1,12,16)\n",
    "    else:\n",
    "        return datetime(start,1,16), datetime(end,1,16)\n",
    "\n",
    "#finding all the models that have ensembles for that experiment.\n",
    "def get_models_for_experiment(experiment):\n",
    "    if experiment == 'historical':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-aer':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','CNRM-CM6-1','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-GHG':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','CNRM-CM6-1','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-sol':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-totalO3':\n",
    "        model = ['CanESM5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-volc':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "        \n",
    "    return model\n",
    "\n",
    "#Cropping CVDP data to the North Atlantic sector - requires some shifting of 0 of the lat lon coordinate system.\n",
    "def CVDP_EM_crop_NA_sector(filename, pattern):\n",
    "    #function which will crop the historical ensemble mean CVDP output to the NA sector\n",
    "    ds = xr.open_dataset(filename)\n",
    "    ds = ds[pattern]\n",
    "    \n",
    "    #finding the longitudes that are greater than 180\n",
    "    new_lon = np.where(ds.lon > 179, ds.lon -360, ds.lon)\n",
    "    \n",
    "    #creating a copy of the data array where the longitudes have been shifted\n",
    "    ds_shifted = ds.copy()\n",
    "    ds_shifted.coords['lon'] = new_lon\n",
    "    \n",
    "    #Now need to make sure they are in the correct order and then re-index to make sure the lon get put to match the sorted lon\n",
    "    sorted_lon = np.sort(ds_shifted.lon)\n",
    "    ds_shifted = ds_shifted.sel(lon=sorted_lon)\n",
    "    \n",
    "    historical_NAO_EM_shifted = ds_shifted.sel(lat=slice(20,80), lon=slice(-90,40))\n",
    "\n",
    "    return historical_NAO_EM_shifted\n",
    "\n",
    "#Crops to the North Atlantic sector - for the LESFMIP data NOT processed by CVDP\n",
    "def open_cropNA_unitshPA(filename):\n",
    "    #function to crop an ensemble member to the north atlantic region\n",
    "    data = xr.open_dataset(filename)\n",
    "    data_NA = data.sel(lat=slice(20,80), lon=slice(-90,40))/100\n",
    "\n",
    "    return data_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc9b16f-c17e-4c4c-be0f-e752d43f386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the seasonal and annual ensemble spatial means.\n",
    "\n",
    "def calculate_spatial_ensemble_mean(file_paths, output_file, variable):\n",
    "    #Will be passing through an experiment's model's ensembles.\n",
    "    #opens all the files given by filepath (basically opens all the ensembles)\n",
    "    ds = xr.open_mfdataset(file_paths, combine='nested', concat_dim='ensemble')\n",
    "\n",
    "    #calculate the mean\n",
    "    mean = ds[variable].mean(dim='ensemble')\n",
    "\n",
    "    #save the ensemble mean to the a .nc file\n",
    "    mean.to_netcdf(output_file)\n",
    "    print('saved')\n",
    "\n",
    "    ds.close()\n",
    "    return mean\n",
    "\n",
    "def calculate_seasonal_spatial_ensemble_mean_djf(file_path, var, seas, output_file, year_init, year_final):\n",
    "    #opening dataset\n",
    "    print('in function')\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    \n",
    "    #checking it is a datetime object\n",
    "    ds['time'] = xr.decode_cf(ds).time\n",
    "\n",
    "    calendar = type(ds.time.values[0])\n",
    "    \n",
    "    start,end = get_time_bounds(calendar, year_init, year_final)\n",
    "\n",
    "    #selecting the psl variable within time bounds\n",
    "    variable = ds[var].sel(time=slice(start, end))\n",
    "    \n",
    "    #Filter for the desired season (e.g., DJF)\n",
    "    season_mask = variable.time.dt.season == seas\n",
    "    ds_months_seas = variable.sel(time=season_mask)\n",
    "    \n",
    "    #assign and adjust year (DJF split over two years so increasing the year of december and then grouping and finding the mean)\n",
    "    ds_months_seas = ds_months_seas.assign_coords(year=ds_months_seas['time'].dt.year)\n",
    "    ds_months_seas['year'] = ds_months_seas['year'].where(ds_months_seas['time'].dt.month != 12, ds_months_seas['year'] + 1)\n",
    "    #ds_months_seas = ds_months_seas.set_coords('year')\n",
    "    \n",
    "    # average over DJF months for each year\n",
    "    ds_season = ds_months_seas.groupby('year').mean(dim='time')\n",
    "    ds_season.to_netcdf(output_file)\n",
    "    print('saved file')\n",
    "    return ds_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae7eb3a-3a16-4297-8245-09a2195c96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions defined for calculating the linear trend\n",
    "def calculate_linear_trend_spat_pattern(file_path, variable, output_file):\n",
    "    # Open dataset and extract variable\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    da = ds[variable]\n",
    "\n",
    "    time = ds['year'].values\n",
    "    lat = ds['lat'].values\n",
    "    lon = ds['lon'].values\n",
    "    time_numeric = np.arange(len(time))\n",
    "\n",
    "    slope = np.full((len(lat), len(lon)), np.nan)\n",
    "    intercept = np.full((len(lat), len(lon)), np.nan)\n",
    "    p_value = np.full((len(lat), len(lon)), np.nan)\n",
    "    stderr = np.full((len(lat), len(lon)), np.nan)\n",
    "\n",
    "    for i in range(len(lat)):\n",
    "        for j in range(len(lon)):\n",
    "            ts = da[:, i, j].values\n",
    "            if np.all(np.isfinite(ts)):\n",
    "                reg = linregress(time_numeric, ts)\n",
    "                slope[i, j] = reg.slope\n",
    "                intercept[i, j] = reg.intercept\n",
    "                p_value[i, j] = reg.pvalue\n",
    "                stderr[i, j] = reg.stderr\n",
    "\n",
    "    from scipy.stats import t\n",
    "    n = len(time_numeric)\n",
    "    df = n - 2\n",
    "    alpha = 0.05\n",
    "    t_crit = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "    ci_lower = slope - t_crit * stderr\n",
    "    ci_upper = slope + t_crit * stderr\n",
    "\n",
    "    slope_da = xr.DataArray(slope, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope\")\n",
    "    intercept_da = xr.DataArray(intercept, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"intercept\")\n",
    "    p_value_da = xr.DataArray(p_value, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"p_value\")\n",
    "    ci_lower_da = xr.DataArray(ci_lower, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_lower\")\n",
    "    ci_upper_da = xr.DataArray(ci_upper, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_upper\")\n",
    "\n",
    "    # Save to one combined netCDF file\n",
    "    combined_ds = xr.Dataset({\n",
    "        \"slope\": slope_da,\n",
    "        \"intercept\": intercept_da,\n",
    "        \"p_value\": p_value_da,\n",
    "        \"slope_CI_lower\": ci_lower_da,\n",
    "        \"slope_CI_upper\": ci_upper_da\n",
    "    })\n",
    "    combined_ds.to_netcdf(output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8661f5d2-4c85-48be-9828-8494f9fc6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the regression map\n",
    "def calculate_regression_map(anomalies, trend, mode, trend_var, e, m, period):\n",
    "    #this will project a trend onto the regression map.\n",
    "    #psl anomalies are linearly regressed onto the PC timeseries (the amount that the EOF's amplitude changes with time)\n",
    "\n",
    "    #setting up output files paths for the projection and the residual\n",
    "    output_regression_map = '/gws/nopw/j04/extant/users/slbennie/regression_patterns/'+mode+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_regression_map_'+period+'.nc'\n",
    "    output_EOF = '/gws/nopw/j04/extant/users/slbennie/regression_patterns/'+mode+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_EOF_pattern_'+period+'.nc'\n",
    "\n",
    "\n",
    "    #selecting the mode of which EOF to calculate\n",
    "    if mode == 'NAO':\n",
    "        mode_number = 0\n",
    "    elif mode == 'EA':\n",
    "        mode_number = 1\n",
    "\n",
    "    #opening up all anomaly files and cropping to NA and converting into hPa (anomaly data is in Pa)\n",
    "    anomaly_list = [open_cropNA_unitshPA(f) for f in anomalies]\n",
    "\n",
    "    #selecting the psl data and concatenating list of data arrays.\n",
    "    all_anomalies = xr.concat(anomaly_list, dim='ensemble')['psl']  # Shape: (ensemble, time, lat, lon)\n",
    "    print(all_anomalies.dims)\n",
    "        \n",
    "    #Flatten ensemble and year into one time dimension (needs to be called time for the pcs function to work later)\n",
    "    all_anomalies_stacked = all_anomalies.stack(time=('ensemble', 'year'))\n",
    "    all_anomalies_stacked = all_anomalies_stacked.reset_index('time', drop=True)\n",
    "    all_anomalies_stacked = all_anomalies_stacked.transpose('time', 'lat', 'lon')\n",
    "\n",
    "    #basically weighting so that each grid cell has influence actually proportional to its area\n",
    "    coslat = np.cos(np.deg2rad(all_anomalies_stacked.coords['lat'].values)).clip(0., 1.)\n",
    "    wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "\n",
    "    #EOF solver\n",
    "    solver = Eof(all_anomalies_stacked, weights=wgts)\n",
    "    \n",
    "    #finding the pattern of the EOF - unitless\n",
    "    EOF_pattern = solver.eofs(neofs=mode_number+1).sel(mode=mode_number)\n",
    "        \n",
    "    #getting the EA Pattern's PC\n",
    "    #using pcscaling=1 for a normalised PC. If not normalised need to divide by the variance of PC ((pc.std(dim='time'))**2) to find the regression map.\n",
    "    pc = solver.pcs(npcs=mode_number+1, pcscaling=1).sel(mode=mode_number)\n",
    "        \n",
    "    #finding regression_map = pattern of psl anomalies regressed onto EA PC, kinda which bits of the trend link to this pattern, units of hPa/unit of PC\n",
    "    #how psl anomalies change spatially for a one-unit change in the PC\n",
    "    regression_map = (all_anomalies_stacked * pc).mean(dim='time')\n",
    "\n",
    "    #making sure that the patterns match what they should for the NAO and EA patterns (basically fixing for sign conventions to make sure physical)\n",
    "    if mode == 'NAO' and regression_map.sel(lat=50, lon=-30, method='nearest') < 0:\n",
    "        regression_map *= -1\n",
    "        pc *= -1\n",
    "\n",
    "    if mode == 'NAO' and regression_map.sel(lat=50, lon=-25, method='nearest') > 0:\n",
    "        regression_map *= -1\n",
    "        pc *= -1\n",
    "        \n",
    "    #outputting .nc files for plotting\n",
    "\n",
    "    \n",
    "    regression_map.name = 'regression_'+mode+'_djf'\n",
    "    #regression_map.to_netcdf(output_regression_map)\n",
    "    EOF_pattern.name = 'EOF_'+mode+'_djf'\n",
    "    EOF_pattern.to_netcdf(output_EOF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f147d4f4-8bd0-47c8-ad9f-eba97e905596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions defined for calculating the projections\n",
    "def project_onto_regression(trend_raw, regression_map, trend_var, mode, e, m, period):\n",
    "    #function which will project a trend (lat,lon) in hPa onto a spatial pattern (lat,lon) hPa to get a single NAO index value\n",
    "    #will then calculate the residual (trend - mode_congruent part) and saves both the NAO congruent part and the residual\n",
    "    #in the same folder, output_file is for the NAO/EA_congruent part filename\n",
    "    #can then change the input spat pattern to calculate the projection onto other eofs, e.g. the EAP\n",
    "\n",
    "\n",
    "    if isinstance(trend_raw, xr.DataArray):\n",
    "        trend = trend_raw\n",
    "    else:\n",
    "        print('here')\n",
    "        trend = trend_raw[trend_var]\n",
    "        \n",
    "    # Weight psl data by coslat to account for grid cell area decreasing with latitude\n",
    "    weights = np.cos(np.radians(trend[\"lat\"].values))\n",
    "    weights_2d = weights[:, np.newaxis]\n",
    "\n",
    "    # weight psl (or another variable) anomalies by area of each gridcell\n",
    "    weighted_trend = trend * weights_2d\n",
    "    weighted_regression = regression_map * weights_2d\n",
    "\n",
    "    # flatten both of the fields so that they are both 1D\n",
    "    trend_flat = weighted_trend.stack(spatial=('lat','lon'))\n",
    "    regression_flat = weighted_regression.stack(spatial=('lat','lon'))\n",
    "\n",
    "    #replace any NaNs with zeros to stop any weird stuff happening\n",
    "    trend_flat = trend_flat.fillna(0)\n",
    "    regression_flat = regression_flat.fillna(0)\n",
    "\n",
    "    #Now do the dot product which is the projection\n",
    "    dot_product = (trend_flat * regression_flat).sum().item()\n",
    "\n",
    "    #calculating the index - or I guess the PC?????\n",
    "    index = dot_product / (regression_flat**2).sum().item()\n",
    "\n",
    "    #Now multiplying the pattern by the index and returning that too\n",
    "    projection = index * regression_map\n",
    "    residual = trend - projection\n",
    "    \n",
    "    projection.name = 'projection_'+mode+'_djf'\n",
    "    residual.name = 'residual_'+mode+'_djf'\n",
    "\n",
    "    output_projection = '/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/'+e+'/'+m+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_projection_'+period+'.nc'\n",
    "    output_residual = '/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/'+e+'/'+m+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_residual_'+period+'.nc'\n",
    "    \n",
    "    #outputting .nc files for plotting\n",
    "    projection.to_netcdf(output_projection)\n",
    "    residual.to_netcdf(output_residual)\n",
    "    \n",
    "    return projection, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868e1d3f-3a53-4616-a396-caddeb10dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_onto_pattern(trend_raw, pattern, trend_var, mode, e, m, period, pattern_type='EOF', save_files=True):\n",
    "    \"\"\"\n",
    "    Project a trend (lat,lon) in hPa onto a spatial pattern (lat,lon) in hPa\n",
    "    pattern_type: 'regression' or 'EOF' (for naming and saving purposes)\n",
    "    Returns:\n",
    "        projection (xr.DataArray)\n",
    "        residual (xr.DataArray)\n",
    "        index (float): projection coefficient or PC amplitude\n",
    "    \"\"\"\n",
    "    if isinstance(trend_raw, xr.DataArray):\n",
    "        trend = trend_raw\n",
    "    else:\n",
    "        trend = trend_raw[trend_var]\n",
    "\n",
    "    # Weight psl data by coslat to account for grid cell area decreasing with latitude\n",
    "    weights = np.cos(np.radians(trend[\"lat\"].values))\n",
    "    weights_2d = weights[:, np.newaxis]\n",
    "\n",
    "    # Weight the fields by grid cell area\n",
    "    weighted_trend = trend * weights_2d\n",
    "    weighted_pattern = pattern * weights_2d\n",
    "\n",
    "    # Flatten spatial dims\n",
    "    trend_flat = weighted_trend.stack(spatial=('lat', 'lon')).fillna(0)\n",
    "    pattern_flat = weighted_pattern.stack(spatial=('lat', 'lon')).fillna(0)\n",
    "\n",
    "    # Dot product for projection coefficient\n",
    "    dot_product = (trend_flat * pattern_flat).sum().item()\n",
    "    index = dot_product / (pattern_flat ** 2).sum().item()\n",
    "\n",
    "    # Projection and residual\n",
    "    projection = index * pattern\n",
    "    residual = trend - projection\n",
    "\n",
    "    # Naming the outputs\n",
    "    projection.name = f'projection_{mode}_{pattern_type}'\n",
    "    residual.name = f'residual_{mode}_{pattern_type}'\n",
    "\n",
    "    if save_files:\n",
    "        output_projection = f'/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/{e}/{m}/psl_mon_{e}_{m}_DJF_{mode}_{pattern_type}_projection_{period}.nc'\n",
    "        output_residual = f'/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/{e}/{m}/psl_mon_{e}_{m}_DJF_{mode}_{pattern_type}_residual_{period}.nc'\n",
    "\n",
    "        projection.to_netcdf(output_projection)\n",
    "        residual.to_netcdf(output_residual)\n",
    "\n",
    "    return projection, residual, index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a243433-6e38-4a71-8428-7076cf92c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the experiments and choose a single mode? could just go ahead and calculate for all of them\n",
    "#trend over the whole period?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b19a671-b5a6-4c36-a85a-5de458e5a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the spatial ensemble means and trends for experiment e: historical\n",
      "Model:  MPI-ESM1-2-LR\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/gws/nopw/j04/extant/users/slbennie/trend_calc_LESFMIP/linear_regression/NAO/historical/MPI-ESM1-2-LR/psl_mon_historical_MPI-ESM1-2-LR_DJF_linear_trend_1850-2015_stats.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/gws/nopw/j04/extant/users/slbennie/trend_calc_LESFMIP/linear_regression/NAO/historical/MPI-ESM1-2-LR/psl_mon_historical_MPI-ESM1-2-LR_DJF_linear_trend_1850-2015_stats.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '047bc914-1ebd-4bd2-ac20-f13c8f289690']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path) \u001b[38;5;28;01mif\u001b[39;00m seas \u001b[38;5;129;01min\u001b[39;00m filename \u001b[38;5;129;01mand\u001b[39;00m period \u001b[38;5;129;01min\u001b[39;00m filename][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m         output_file \u001b[38;5;241m=\u001b[39m home\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrend_calc_LESFMIP/linear_regression/NAO/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39me\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mm\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mvariable\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mon_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39me\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mm\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mseas\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_linear_trend_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mperiod\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_stats.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 39\u001b[0m         \u001b[43mcalculate_linear_trend_spat_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#now creating the NAO and EA regression maps\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#find the trend and crop to NA Sector, sort units.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m, in \u001b[0;36mcalculate_linear_trend_spat_pattern\u001b[0;34m(file_path, variable, output_file)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Save to one combined netCDF file\u001b[39;00m\n\u001b[1;32m     43\u001b[0m combined_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset({\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslope\u001b[39m\u001b[38;5;124m\"\u001b[39m: slope_da,\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m\"\u001b[39m: intercept_da,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslope_CI_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m: ci_upper_da\n\u001b[1;32m     49\u001b[0m })\n\u001b[0;32m---> 50\u001b[0m \u001b[43mcombined_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/core/dataset.py:2329\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2337\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2340\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/api.py:1343\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1342\u001b[0m         )\n\u001b[0;32m-> 1343\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mstore_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:408\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    403\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    406\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    407\u001b[0m )\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:355\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:417\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:411\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/gws/nopw/j04/extant/users/slbennie/trend_calc_LESFMIP/linear_regression/NAO/historical/MPI-ESM1-2-LR/psl_mon_historical_MPI-ESM1-2-LR_DJF_linear_trend_1850-2015_stats.nc'"
     ]
    }
   ],
   "source": [
    "#notes find a way to update period so its nicer.\n",
    "#also could fix folder so that I use like a home dir etc.\n",
    "#anomalies have already been calculated separetly for each model so preusming they are all correct this should run?...\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol','hist-totalO3','hist-volc']\n",
    "model = ['HadGEM3-GC31-LL']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for e in experiment:\n",
    "    print('Calculating the spatial ensemble means and trends for experiment e:', e)\n",
    "    for m in model:\n",
    "        print('Model: ',m)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        output_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        output_file_djf = output_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, output_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(output_file, variable, seas, output_file_djf, 1850, 2015)\n",
    "\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n",
    "\n",
    "#now creating the NAO and EA regression maps\n",
    "for m in model:\n",
    "    #find the trend and crop to NA Sector, sort units.\n",
    "    trend_filename = home+'trend_calc_LESFMIP/linear_regression/NAO/historical/'+m+'/'+variable+'_mon_historical_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    trend = open_cropNA_unitshPA(trend_filename) * 165 #converts from Pa/year to hPa (the function converts from Pa to hPa so need to multiply by 165 for the hPa not hPa/year)\n",
    "\n",
    "    #path to the folder containing each experiment and model's psl anomalies (calculated seperatley)\n",
    "    folder_path = f'{home}psl_anomalies/{e}/{m}/'\n",
    "\n",
    "    #creating the list of files for this experiment and model's psl anomalies\n",
    "    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "\n",
    "    calculate_regression_map(ens_files, trend, 'NAO', 'slope', e, m, period)\n",
    "    calculate_regression_map(ens_files, trend, 'EA', 'slope', e, m, period)\n",
    "\n",
    "experiment = ['hist-aer','hist-GHG','hist-sol','hist-totalO3','hist-volc']\n",
    "\n",
    "#Now re-opening these maps and projecting the trends onto them\n",
    "for m in model:\n",
    "    print('Model:', m)\n",
    "    regression_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_regression_map_'+period+'.nc')\n",
    "    regression_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_regression_map_'+period+'.nc')\n",
    "\n",
    "    for e in experiment:\n",
    "        print(\"Calculating the projection of the forced trend onto historical regression map calculated from all ensembles:\", e)\n",
    "        \n",
    "        #now setting up the folder path to get the file names for each experiment's model's forced response's trend\n",
    "        folder_path = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'\n",
    "            \n",
    "        #Getting the list of file names within the models folder, should only be one trend per model (working off the ensemble means for each model)\n",
    "        ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and period in filename]\n",
    "            \n",
    "        for i in range(0,len(ens_files)):\n",
    "            #cropping each trend to just the NA sector and whichever time\n",
    "            trend = open_cropNA_unitshPA(ens_files[i])#, 1850,2014)\n",
    "    \n",
    "            #multiplying the trend by 165 to convert to units of hPa (currently in units of hPa/year, trend calculated between 1850-2015)\n",
    "            trend = trend * 165\n",
    "\n",
    "            #calling the projection functions\n",
    "            proj_NAO, residual_NAO = project_onto_regression(trend, regression_NAO['regression_NAO_djf'], 'slope', 'NAO', e, m, period)\n",
    "            proj_EA, residual_EA = project_onto_regression(residual_NAO, regression_EA['regression_EA_djf'], 'slope', 'EA', e, m, period)\n",
    "\n",
    "#print(residual_NAO, residual_EA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f68b70a-ef1f-4e9c-8bdb-ff7850d3fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: HadGEM3-GC31-LL\n",
      "Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles: historical\n",
      "Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles: hist-aer\n",
      "Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles: hist-GHG\n",
      "Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles: hist-sol\n",
      "Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles: hist-totalO3\n",
      "Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles: hist-volc\n"
     ]
    }
   ],
   "source": [
    "#notes find a way to update period so its nicer.\n",
    "#also could fix folder so that I use like a home dir etc.\n",
    "#anomalies have already been calculated separetly for each model so preusming they are all correct this should run?...\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol','hist-totalO3','hist-volc']\n",
    "model = ['HadGEM3-GC31-LL']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "\n",
    "#now creating the NAO and EA EOFpatterns\n",
    "#for m in model:\n",
    "#    #find the trend and crop to NA Sector, sort units.\n",
    "#    trend_filename = home+'trend_calc_LESFMIP/linear_regression/NAO/historical/'+m+'/'+variable+'_mon_historical_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "#    trend = open_cropNA_unitshPA(trend_filename) * 165 #converts from Pa/year to hPa (the function converts from Pa to hPa so need to multiply by 165 for the hPa not hPa/year)\n",
    "\n",
    "#    #path to the folder containing each experiment and model's psl anomalies (calculated seperatley)\n",
    "#    folder_path = f'{home}psl_anomalies/{e}/{m}/'\n",
    "\n",
    "#    #creating the list of files for this experiment and model's psl anomalies\n",
    "#    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "\n",
    "#    calculate_regression_map(ens_files, trend, 'NAO', 'slope', e, m, period)\n",
    "#    calculate_regression_map(ens_files, trend, 'EA', 'slope', e, m, period)\n",
    "\n",
    "#experiment = ['hist-aer','hist-GHG','hist-sol','hist-totalO3','hist-volc']\n",
    "\n",
    "#Now re-opening these maps and projecting the trends onto them\n",
    "for m in model:\n",
    "    print('Model:', m)\n",
    "    EOF_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_EOF_pattern_'+period+'.nc')\n",
    "    EOF_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_EOF_pattern_'+period+'.nc')\n",
    "\n",
    "    for e in experiment:\n",
    "        print(\"Calculating the projection of the forced trend onto historical EOF pattern calculated from all ensembles:\", e)\n",
    "        \n",
    "        #now setting up the folder path to get the file names for each experiment's model's forced response's trend\n",
    "        folder_path = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'\n",
    "            \n",
    "        #Getting the list of file names within the models folder, should only be one trend per model (working off the ensemble means for each model)\n",
    "        ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and period in filename]\n",
    "            \n",
    "        for i in range(0,len(ens_files)):\n",
    "            #cropping each trend to just the NA sector and whichever time\n",
    "            trend = open_cropNA_unitshPA(ens_files[i])#, 1850,2014)\n",
    "    \n",
    "            #multiplying the trend by 165 to convert to units of hPa (currently in units of hPa/year, trend calculated between 1850-2015)\n",
    "            trend = trend * 165\n",
    "\n",
    "            #calling the projection functions\n",
    "            proj_NAO, residual_NAO, NAO_index = project_onto_pattern(trend, EOF_NAO['EOF_NAO_djf'], 'slope', 'NAO', e, m, period,'EOF', True)\n",
    "            proj_EA, residual_EA, EA_index = project_onto_pattern(residual_NAO, EOF_EA['EOF_EA_djf'], 'slope', 'EA', e, m, period, 'EOF', True)\n",
    "\n",
    "#print(residual_NAO, residual_EA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fbbf5ad-fd17-4a66-9cef-a716a0c0f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the spatial ensemble means and trends for experiment e: historical\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-aer\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-GHG\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-sol\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n"
     ]
    }
   ],
   "source": [
    "#had to re-do these ones for the means.\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1950-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol']\n",
    "model = ['CanESM5']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for e in experiment:\n",
    "    print('Calculating the spatial ensemble means and trends for experiment e:', e)\n",
    "    for m in model:\n",
    "        print('Model: ',m)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        output_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        output_file_djf = output_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, output_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(output_file, variable, seas, output_file_djf, 1850, 2015)\n",
    "\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956da97-e2e1-43b7-be02-56eb92b971ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
