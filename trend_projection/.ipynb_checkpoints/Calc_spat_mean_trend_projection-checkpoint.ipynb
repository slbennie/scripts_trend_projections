{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1addd5f-6e2a-43fa-82f8-b155037c3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import linregress\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe5a59a-c91a-4956-9ee3-e202c8f4e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the correct calendar (model dependent.)\n",
    "def get_time_bounds(calendar_type, start, end):\n",
    "    #1850-2015 all of 2014 - none of 2015.\n",
    "    if calendar_type == cftime.DatetimeNoLeap:\n",
    "        return cftime.DatetimeNoLeap(start,1,16), cftime.DatetimeNoLeap(end,1,16)\n",
    "    elif calendar_type == cftime.Datetime360Day:\n",
    "        return cftime.Datetime360Day(start,1,16), cftime.Datetime360Day(end-1,12,16)\n",
    "    else:\n",
    "        return datetime(start,1,16), datetime(end,1,16)\n",
    "\n",
    "#finding all the models that have ensembles for that experiment.\n",
    "def get_models_for_experiment(experiment):\n",
    "    if experiment == 'historical':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-aer':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','CNRM-CM6-1','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-GHG':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','CNRM-CM6-1','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-sol':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-totalO3':\n",
    "        model = ['CanESM5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-volc':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "        \n",
    "    return model\n",
    "\n",
    "#Cropping CVDP data to the North Atlantic sector - requires some shifting of 0 of the lat lon coordinate system.\n",
    "def CVDP_EM_crop_NA_sector(filename, pattern):\n",
    "    #function which will crop the historical ensemble mean CVDP output to the NA sector\n",
    "    ds = xr.open_dataset(filename)\n",
    "    ds = ds[pattern]\n",
    "    \n",
    "    #finding the longitudes that are greater than 180\n",
    "    new_lon = np.where(ds.lon > 179, ds.lon -360, ds.lon)\n",
    "    \n",
    "    #creating a copy of the data array where the longitudes have been shifted\n",
    "    ds_shifted = ds.copy()\n",
    "    ds_shifted.coords['lon'] = new_lon\n",
    "    \n",
    "    #Now need to make sure they are in the correct order and then re-index to make sure the lon get put to match the sorted lon\n",
    "    sorted_lon = np.sort(ds_shifted.lon)\n",
    "    ds_shifted = ds_shifted.sel(lon=sorted_lon)\n",
    "    \n",
    "    historical_NAO_EM_shifted = ds_shifted.sel(lat=slice(20,80), lon=slice(-90,40))\n",
    "\n",
    "    return historical_NAO_EM_shifted\n",
    "\n",
    "#Crops to the North Atlantic sector - for the LESFMIP data NOT processed by CVDP\n",
    "def open_cropNA_unitshPA(filename):\n",
    "    #function to crop an ensemble member to the north atlantic region\n",
    "    data = xr.open_dataset(filename)\n",
    "    data_NA = data.sel(lat=slice(20,80), lon=slice(-90,40))/100\n",
    "\n",
    "    return data_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc9b16f-c17e-4c4c-be0f-e752d43f386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the seasonal and annual ensemble spatial means.\n",
    "\n",
    "def calculate_spatial_ensemble_mean(file_paths, output_file, variable):\n",
    "    #Will be passing through an experiment's model's ensembles.\n",
    "    #opens all the files given by filepath (basically opens all the ensembles)\n",
    "    ds = xr.open_mfdataset(file_paths, combine='nested', concat_dim='ensemble')\n",
    "\n",
    "    #calculate the mean\n",
    "    mean = ds[variable].mean(dim='ensemble')\n",
    "\n",
    "    #save the ensemble mean to the a .nc file\n",
    "    mean.to_netcdf(output_file)\n",
    "    print('saved')\n",
    "\n",
    "    ds.close()\n",
    "    return mean\n",
    "\n",
    "def calculate_seasonal_spatial_ensemble_mean_djf(file_path, var, seas, output_file, year_init, year_final):\n",
    "    #opening dataset\n",
    "    print('in function')\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    \n",
    "    #checking it is a datetime object\n",
    "    ds['time'] = xr.decode_cf(ds).time\n",
    "\n",
    "    calendar = type(ds.time.values[0])\n",
    "    \n",
    "    start,end = get_time_bounds(calendar, year_init, year_final)\n",
    "\n",
    "    #selecting the psl variable within time bounds\n",
    "    variable = ds[var].sel(time=slice(start, end))\n",
    "    \n",
    "    #Filter for the desired season (e.g., DJF)\n",
    "    season_mask = variable.time.dt.season == seas\n",
    "    ds_months_seas = variable.sel(time=season_mask)\n",
    "    \n",
    "    #assign and adjust year (DJF split over two years so increasing the year of december and then grouping and finding the mean)\n",
    "    ds_months_seas = ds_months_seas.assign_coords(year=ds_months_seas['time'].dt.year)\n",
    "    ds_months_seas['year'] = ds_months_seas['year'].where(ds_months_seas['time'].dt.month != 12, ds_months_seas['year'] + 1)\n",
    "    #ds_months_seas = ds_months_seas.set_coords('year')\n",
    "    \n",
    "    # average over DJF months for each year\n",
    "    ds_season = ds_months_seas.groupby('year').mean(dim='time')\n",
    "    ds_season.to_netcdf(output_file)\n",
    "    print('saved file')\n",
    "    return ds_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae7eb3a-3a16-4297-8245-09a2195c96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions defined for calculating the linear trend\n",
    "def calculate_linear_trend_spat_pattern(file_path, variable, output_file):\n",
    "    # Open dataset and extract variable\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    da = ds[variable]\n",
    "\n",
    "    time = ds['year'].values\n",
    "    lat = ds['lat'].values\n",
    "    lon = ds['lon'].values\n",
    "    time_numeric = np.arange(len(time))\n",
    "\n",
    "    slope = np.full((len(lat), len(lon)), np.nan)\n",
    "    intercept = np.full((len(lat), len(lon)), np.nan)\n",
    "    p_value = np.full((len(lat), len(lon)), np.nan)\n",
    "    stderr = np.full((len(lat), len(lon)), np.nan)\n",
    "\n",
    "    for i in range(len(lat)):\n",
    "        for j in range(len(lon)):\n",
    "            ts = da[:, i, j].values\n",
    "            if np.all(np.isfinite(ts)):\n",
    "                reg = linregress(time_numeric, ts)\n",
    "                slope[i, j] = reg.slope\n",
    "                intercept[i, j] = reg.intercept\n",
    "                p_value[i, j] = reg.pvalue\n",
    "                stderr[i, j] = reg.stderr\n",
    "\n",
    "    from scipy.stats import t\n",
    "    n = len(time_numeric)\n",
    "    df = n - 2\n",
    "    alpha = 0.05\n",
    "    t_crit = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "    ci_lower = slope - t_crit * stderr\n",
    "    ci_upper = slope + t_crit * stderr\n",
    "\n",
    "    slope_da = xr.DataArray(slope, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope\")\n",
    "    intercept_da = xr.DataArray(intercept, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"intercept\")\n",
    "    p_value_da = xr.DataArray(p_value, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"p_value\")\n",
    "    ci_lower_da = xr.DataArray(ci_lower, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_lower\")\n",
    "    ci_upper_da = xr.DataArray(ci_upper, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_upper\")\n",
    "\n",
    "    # Save to one combined netCDF file\n",
    "    combined_ds = xr.Dataset({\n",
    "        \"slope\": slope_da,\n",
    "        \"intercept\": intercept_da,\n",
    "        \"p_value\": p_value_da,\n",
    "        \"slope_CI_lower\": ci_lower_da,\n",
    "        \"slope_CI_upper\": ci_upper_da\n",
    "    })\n",
    "    combined_ds.to_netcdf(output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8661f5d2-4c85-48be-9828-8494f9fc6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the regression map\n",
    "def calculate_regression_map(anomalies, trend, mode, trend_var, e, m, period):\n",
    "    #this will project a trend onto the regression map.\n",
    "    #psl anomalies are linearly regressed onto the PC timeseries (the amount that the EOF's amplitude changes with time)\n",
    "\n",
    "    #setting up output files paths for the projection and the residual\n",
    "    output_regression_map = '/gws/nopw/j04/extant/users/slbennie/regression_patterns/'+mode+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_regression_map_'+period+'.nc'\n",
    "\n",
    "\n",
    "    #selecting the mode of which EOF to calculate\n",
    "    if mode == 'NAO':\n",
    "        mode_number = 0\n",
    "    elif mode == 'EA':\n",
    "        mode_number = 1\n",
    "\n",
    "    #opening up all anomaly files and cropping to NA and converting into hPa (anomaly data is in Pa)\n",
    "    anomaly_list = [open_cropNA_unitshPA(f) for f in anomalies]\n",
    "\n",
    "    #selecting the psl data and concatenating list of data arrays.\n",
    "    all_anomalies = xr.concat(anomaly_list, dim='ensemble')['psl']  # Shape: (ensemble, time, lat, lon)\n",
    "    print(all_anomalies.dims)\n",
    "        \n",
    "    #Flatten ensemble and year into one time dimension (needs to be called time for the pcs function to work later)\n",
    "    all_anomalies_stacked = all_anomalies.stack(time=('ensemble', 'year'))\n",
    "    all_anomalies_stacked = all_anomalies_stacked.reset_index('time', drop=True)\n",
    "    all_anomalies_stacked = all_anomalies_stacked.transpose('time', 'lat', 'lon')\n",
    "\n",
    "    #basically weighting so that each grid cell has influence actually proportional to its area\n",
    "    coslat = np.cos(np.deg2rad(all_anomalies_stacked.coords['lat'].values)).clip(0., 1.)\n",
    "    wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "\n",
    "    #EOF solver\n",
    "    solver = Eof(all_anomalies_stacked, weights=wgts)\n",
    "    \n",
    "    #finding the pattern of the EOF - unitless\n",
    "    EOF_pattern = solver.eofs(neofs=mode_number+1).sel(mode=mode_number)\n",
    "        \n",
    "    #getting the EA Pattern's PC\n",
    "    #using pcscaling=1 for a normalised PC. If not normalised need to divide by the variance of PC ((pc.std(dim='time'))**2) to find the regression map.\n",
    "    pc = solver.pcs(npcs=mode_number+1, pcscaling=1).sel(mode=mode_number)\n",
    "        \n",
    "    #finding regression_map = pattern of psl anomalies regressed onto EA PC, kinda which bits of the trend link to this pattern, units of hPa/unit of PC\n",
    "    #how psl anomalies change spatially for a one-unit change in the PC\n",
    "    regression_map = (all_anomalies_stacked * pc).mean(dim='time')\n",
    "\n",
    "    #making sure that the patterns match what they should for the NAO and EA patterns (basically fixing for sign conventions to make sure physical)\n",
    "    if mode == 'NAO' and regression_map.sel(lat=50, lon=-30, method='nearest') < 0:\n",
    "        regression_map *= -1\n",
    "        pc *= -1\n",
    "\n",
    "    if mode == 'NAO' and regression_map.sel(lat=50, lon=-25, method='nearest') > 0:\n",
    "        regression_map *= -1\n",
    "        pc *= -1\n",
    "        \n",
    "    #outputting .nc files for plotting\n",
    "\n",
    "    \n",
    "    regression_map.name = 'regression_'+mode+'_djf'\n",
    "    regression_map.to_netcdf(output_regression_map)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f147d4f4-8bd0-47c8-ad9f-eba97e905596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions defined for calculating the projections\n",
    "def project_onto_regression(trend_raw, regression_map, trend_var, mode, e, m, period):\n",
    "    #function which will project a trend (lat,lon) in hPa onto a spatial pattern (lat,lon) hPa to get a single NAO index value\n",
    "    #will then calculate the residual (trend - mode_congruent part) and saves both the NAO congruent part and the residual\n",
    "    #in the same folder, output_file is for the NAO/EA_congruent part filename\n",
    "    #can then change the input spat pattern to calculate the projection onto other eofs, e.g. the EAP\n",
    "\n",
    "\n",
    "    if isinstance(trend_raw, xr.DataArray):\n",
    "        trend = trend_raw\n",
    "    else:\n",
    "        print('here')\n",
    "        trend = trend_raw[trend_var]\n",
    "        \n",
    "    # Weight psl data by coslat to account for grid cell area decreasing with latitude\n",
    "    weights = np.cos(np.radians(trend[\"lat\"].values))\n",
    "    weights_2d = weights[:, np.newaxis]\n",
    "\n",
    "    # weight psl (or another variable) anomalies by area of each gridcell\n",
    "    weighted_trend = trend * weights_2d\n",
    "    weighted_regression = regression_map * weights_2d\n",
    "\n",
    "    # flatten both of the fields so that they are both 1D\n",
    "    trend_flat = weighted_trend.stack(spatial=('lat','lon'))\n",
    "    regression_flat = weighted_regression.stack(spatial=('lat','lon'))\n",
    "\n",
    "    #replace any NaNs with zeros to stop any weird stuff happening\n",
    "    trend_flat = trend_flat.fillna(0)\n",
    "    regression_flat = regression_flat.fillna(0)\n",
    "\n",
    "    #Now do the dot product which is the projection\n",
    "    dot_product = (trend_flat * regression_flat).sum().item()\n",
    "\n",
    "    #calculating the index - or I guess the PC?????\n",
    "    index = dot_product / (regression_flat**2).sum().item()\n",
    "\n",
    "    #Now multiplying the pattern by the index and returning that too\n",
    "    projection = index * regression_map\n",
    "    residual = trend - projection\n",
    "    \n",
    "    projection.name = 'projection_'+mode+'_djf'\n",
    "    residual.name = 'residual_'+mode+'_djf'\n",
    "\n",
    "    output_projection = '/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/'+e+'/'+m+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_projection_'+period+'.nc'\n",
    "    output_residual = '/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/'+e+'/'+m+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_residual_'+period+'.nc'\n",
    "    \n",
    "    #outputting .nc files for plotting\n",
    "    projection.to_netcdf(output_projection)\n",
    "    residual.to_netcdf(output_residual)\n",
    "    \n",
    "    return projection, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a243433-6e38-4a71-8428-7076cf92c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the experiments and choose a single mode? could just go ahead and calculate for all of them\n",
    "#trend over the whole period?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b19a671-b5a6-4c36-a85a-5de458e5a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the spatial ensemble means and trends for experiment e: hist-totalO3\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-volc\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "('ensemble', 'year', 'lat', 'lon')\n",
      "('ensemble', 'year', 'lat', 'lon')\n",
      "Model: CanESM5\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-aer\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-GHG\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-sol\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-totalO3\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-volc\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "#notes find a way to update period so its nicer.\n",
    "#also could fix folder so that I use like a home dir etc.\n",
    "#anomalies have already been calculated separetly for each model so preusming they are all correct this should run?...\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['hist-totalO3','hist-volc']\n",
    "model = ['CanESM5']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for e in experiment:\n",
    "    print('Calculating the spatial ensemble means and trends for experiment e:', e)\n",
    "    for m in model:\n",
    "        print('Model: ',m)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        output_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        output_file_djf = output_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, output_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(output_file, variable, seas, output_file_djf, 1850, 2015)\n",
    "\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n",
    "\n",
    "#now creating the NAO adn EA regression maps\n",
    "for m in model:\n",
    "    #find the trend and crop to NA Sector, sort units.\n",
    "    trend_filename = home+'trend_calc_LESFMIP/linear_regression/NAO/historical/'+m+'/'+variable+'_mon_historical_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    trend = open_cropNA_unitshPA(trend_filename) * 165 #converts from Pa/year to hPa (the function converts from Pa to hPa so need to multiply by 165 for the hPa not hPa/year)\n",
    "\n",
    "    #path to the folder containing each experiment and model's psl anomalies (calculated seperatley)\n",
    "    folder_path = f'{home}psl_anomalies/{e}/{m}/'\n",
    "\n",
    "    #creating the list of files for this experiment and model's psl anomalies\n",
    "    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "\n",
    "    calculate_regression_map(ens_files, trend, 'NAO', 'slope', e, m, period)\n",
    "    calculate_regression_map(ens_files, trend, 'EA', 'slope', e, m, period)\n",
    "\n",
    "experiment = ['hist-aer','hist-GHG','hist-sol','hist-totalO3','hist-volc']\n",
    "\n",
    "#Now re-opening these maps and projecting the trends onto them\n",
    "for m in model:\n",
    "    print('Model:', m)\n",
    "    regression_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_regression_map_'+period+'.nc')\n",
    "    regression_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_regression_map_'+period+'.nc')\n",
    "\n",
    "    for e in experiment:\n",
    "        print(\"Calculating the projection of the forced trend onto historical regression map calculated from all ensembles:\", e)\n",
    "        \n",
    "        #now setting up the folder path to get the file names for each experiment's model's forced response's trend\n",
    "        folder_path = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'\n",
    "            \n",
    "        #Getting the list of file names within the models folder, should only be one trend per model (working off the ensemble means for each model)\n",
    "        ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and period in filename]\n",
    "            \n",
    "        for i in range(0,len(ens_files)):\n",
    "            #cropping each trend to just the NA sector and whichever time\n",
    "            trend = open_cropNA_unitshPA(ens_files[i])#, 1850,2014)\n",
    "    \n",
    "            #multiplying the trend by 165 to convert to units of hPa (currently in units of hPa/year, trend calculated between 1850-2015)\n",
    "            trend = trend * 165\n",
    "\n",
    "            #calling the projection functions\n",
    "            proj_NAO, residual_NAO = project_onto_regression(trend, regression_NAO['regression_NAO_djf'], 'slope', 'NAO', e, m, period)\n",
    "            proj_EA, residual_EA = project_onto_regression(residual_NAO, regression_EA['regression_EA_djf'], 'slope', 'EA', e, m, period)\n",
    "\n",
    "#print(residual_NAO, residual_EA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fbbf5ad-fd17-4a66-9cef-a716a0c0f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the spatial ensemble means and trends for experiment e: historical\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-aer\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-GHG\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-sol\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n"
     ]
    }
   ],
   "source": [
    "#had to re-do these ones for the means.\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1950-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol']\n",
    "model = ['CanESM5']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for e in experiment:\n",
    "    print('Calculating the spatial ensemble means and trends for experiment e:', e)\n",
    "    for m in model:\n",
    "        print('Model: ',m)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        output_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        output_file_djf = output_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, output_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(output_file, variable, seas, output_file_djf, 1850, 2015)\n",
    "\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956da97-e2e1-43b7-be02-56eb92b971ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
