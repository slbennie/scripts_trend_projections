{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1addd5f-6e2a-43fa-82f8-b155037c3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import linregress\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe5a59a-c91a-4956-9ee3-e202c8f4e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the correct calendar (model dependent.)\n",
    "def get_time_bounds(calendar_type, start, end):\n",
    "    #1850-2015 all of 2014 - none of 2015.\n",
    "    if calendar_type == cftime.DatetimeNoLeap:\n",
    "        return cftime.DatetimeNoLeap(start,1,16), cftime.DatetimeNoLeap(end,1,16)\n",
    "    elif calendar_type == cftime.Datetime360Day:\n",
    "        return cftime.Datetime360Day(start,1,16), cftime.Datetime360Day(end-1,12,16)\n",
    "    else:\n",
    "        return datetime(start,1,16), datetime(end,1,16)\n",
    "\n",
    "#finding all the models that have ensembles for that experiment.\n",
    "def get_models_for_experiment(experiment):\n",
    "    if experiment == 'historical':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-aer':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','CNRM-CM6-1','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-GHG':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','CNRM-CM6-1','FGOALS-g3','GISS-E2-1-G','HadGEM3-GC31-LL','IPSL-CM6A-LR','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-sol':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-totalO3':\n",
    "        model = ['CanESM5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "    elif experiment == 'hist-volc':\n",
    "        model = ['ACCESS-ESM1-5','CanESM5','CMCC-CM2-SR5','GISS-E2-1-G','HadGEM3-GC31-LL','MIROC6','MPI-ESM1-2-LR','NorESM2-LM']\n",
    "        \n",
    "    return model\n",
    "\n",
    "#Cropping CVDP data to the North Atlantic sector - requires some shifting of 0 of the lat lon coordinate system.\n",
    "def CVDP_EM_crop_NA_sector(filename, pattern):\n",
    "    #function which will crop the historical ensemble mean CVDP output to the NA sector\n",
    "    ds = xr.open_dataset(filename)\n",
    "    ds = ds[pattern]\n",
    "    \n",
    "    #finding the longitudes that are greater than 180\n",
    "    new_lon = np.where(ds.lon > 179, ds.lon -360, ds.lon)\n",
    "    \n",
    "    #creating a copy of the data array where the longitudes have been shifted\n",
    "    ds_shifted = ds.copy()\n",
    "    ds_shifted.coords['lon'] = new_lon\n",
    "    \n",
    "    #Now need to make sure they are in the correct order and then re-index to make sure the lon get put to match the sorted lon\n",
    "    sorted_lon = np.sort(ds_shifted.lon)\n",
    "    ds_shifted = ds_shifted.sel(lon=sorted_lon)\n",
    "    \n",
    "    historical_NAO_EM_shifted = ds_shifted.sel(lat=slice(20,80), lon=slice(-90,40))\n",
    "\n",
    "    return historical_NAO_EM_shifted\n",
    "\n",
    "#Crops to the North Atlantic sector - for the LESFMIP data NOT processed by CVDP\n",
    "def open_cropNA_unitshPA(filename):\n",
    "    #function to crop an ensemble member to the north atlantic region\n",
    "    data = xr.open_dataset(filename)\n",
    "    data_NA = data.sel(lat=slice(20,80), lon=slice(-90,40))/100\n",
    "\n",
    "    return data_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc9b16f-c17e-4c4c-be0f-e752d43f386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the seasonal and annual ensemble spatial means.\n",
    "\n",
    "def calculate_spatial_ensemble_mean(file_paths, output_file, variable):\n",
    "    #Will be passing through an experiment's model's ensembles.\n",
    "    #opens all the files given by filepath (basically opens all the ensembles)\n",
    "    ds = xr.open_mfdataset(file_paths, combine='nested', concat_dim='ensemble')\n",
    "\n",
    "    #calculate the mean\n",
    "    mean = ds[variable].mean(dim='ensemble')\n",
    "\n",
    "    #save the ensemble mean to the a .nc file\n",
    "    mean.to_netcdf(output_file)\n",
    "    print('saved')\n",
    "\n",
    "    ds.close()\n",
    "    return mean\n",
    "\n",
    "def calculate_seasonal_spatial_ensemble_mean_djf(file_path, var, seas, output_file, year_init, year_final):\n",
    "    #opening dataset\n",
    "    print('in function')\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    \n",
    "    #checking it is a datetime object\n",
    "    ds['time'] = xr.decode_cf(ds).time\n",
    "\n",
    "    calendar = type(ds.time.values[0])\n",
    "    \n",
    "    start,end = get_time_bounds(calendar, year_init, year_final)\n",
    "\n",
    "    #selecting the psl variable within time bounds\n",
    "    variable = ds[var].sel(time=slice(start, end))\n",
    "    \n",
    "    #Filter for the desired season (e.g., DJF)\n",
    "    season_mask = variable.time.dt.season == seas\n",
    "    ds_months_seas = variable.sel(time=season_mask)\n",
    "    \n",
    "    #assign and adjust year (DJF split over two years so increasing the year of december and then grouping and finding the mean)\n",
    "    ds_months_seas = ds_months_seas.assign_coords(year=ds_months_seas['time'].dt.year)\n",
    "    ds_months_seas['year'] = ds_months_seas['year'].where(ds_months_seas['time'].dt.month != 12, ds_months_seas['year'] + 1)\n",
    "    #ds_months_seas = ds_months_seas.set_coords('year')\n",
    "    \n",
    "    # average over DJF months for each year\n",
    "    ds_season = ds_months_seas.groupby('year').mean(dim='time')\n",
    "    ds_season.to_netcdf(output_file)\n",
    "    print('saved file')\n",
    "    return ds_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae7eb3a-3a16-4297-8245-09a2195c96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions defined for calculating the linear trend\n",
    "def calculate_linear_trend_spat_pattern(file_path, variable, output_file):\n",
    "    # Open dataset and extract variable\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    da = ds[variable]\n",
    "\n",
    "    time = ds['year'].values\n",
    "    lat = ds['lat'].values\n",
    "    lon = ds['lon'].values\n",
    "    time_numeric = np.arange(len(time))\n",
    "\n",
    "    slope = np.full((len(lat), len(lon)), np.nan)\n",
    "    intercept = np.full((len(lat), len(lon)), np.nan)\n",
    "    p_value = np.full((len(lat), len(lon)), np.nan)\n",
    "    stderr = np.full((len(lat), len(lon)), np.nan)\n",
    "\n",
    "    for i in range(len(lat)):\n",
    "        for j in range(len(lon)):\n",
    "            ts = da[:, i, j].values\n",
    "            if np.all(np.isfinite(ts)):\n",
    "                reg = linregress(time_numeric, ts)\n",
    "                slope[i, j] = reg.slope\n",
    "                intercept[i, j] = reg.intercept\n",
    "                p_value[i, j] = reg.pvalue\n",
    "                stderr[i, j] = reg.stderr\n",
    "\n",
    "    from scipy.stats import t\n",
    "    n = len(time_numeric)\n",
    "    df = n - 2\n",
    "    alpha = 0.05\n",
    "    t_crit = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "    ci_lower = slope - t_crit * stderr\n",
    "    ci_upper = slope + t_crit * stderr\n",
    "\n",
    "    slope_da = xr.DataArray(slope, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope\")\n",
    "    intercept_da = xr.DataArray(intercept, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"intercept\")\n",
    "    p_value_da = xr.DataArray(p_value, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"p_value\")\n",
    "    ci_lower_da = xr.DataArray(ci_lower, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_lower\")\n",
    "    ci_upper_da = xr.DataArray(ci_upper, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_upper\")\n",
    "\n",
    "    # Save to one combined netCDF file\n",
    "    combined_ds = xr.Dataset({\n",
    "        \"slope\": slope_da,\n",
    "        \"intercept\": intercept_da,\n",
    "        \"p_value\": p_value_da,\n",
    "        \"slope_CI_lower\": ci_lower_da,\n",
    "        \"slope_CI_upper\": ci_upper_da\n",
    "    })\n",
    "    combined_ds.to_netcdf(output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8661f5d2-4c85-48be-9828-8494f9fc6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the regression map\n",
    "def calculate_regression_map(anomalies, mode, e, m, period):\n",
    "    #this will find the regression map and EOF pattern.\n",
    "    #psl anomalies are linearly regressed onto the PC timeseries (the amount that the EOF's amplitude changes with time)\n",
    "\n",
    "    print(anomalies)\n",
    "    #setting up output files paths for the projection and the residual\n",
    "    output_regression_map = '/gws/nopw/j04/extant/users/slbennie/regression_patterns/'+mode+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_regression_map_'+period+'.nc'\n",
    "    output_EOF = '/gws/nopw/j04/extant/users/slbennie/regression_patterns/'+mode+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_EOF_pattern_'+period+'.nc'\n",
    "\n",
    "\n",
    "    #selecting the mode of which EOF to calculate\n",
    "    if mode == 'NAO':\n",
    "        mode_number = 0\n",
    "    elif mode == 'EA':\n",
    "        mode_number = 1\n",
    "\n",
    "    #opening up all anomaly files and cropping to NA and converting into hPa (anomaly data is in Pa)\n",
    "    anomaly_list = [open_cropNA_unitshPA(f) for f in anomalies]\n",
    "\n",
    "    #selecting the psl data and concatenating list of data arrays.\n",
    "    all_anomalies = xr.concat(anomaly_list, dim='ensemble')['psl']  # Shape: (ensemble, time, lat, lon)\n",
    "    print(all_anomalies.dims)\n",
    "        \n",
    "    #Flatten ensemble and year into one time dimension (needs to be called time for the pcs function to work later)\n",
    "    all_anomalies_stacked = all_anomalies.stack(time=('ensemble', 'year'))\n",
    "    all_anomalies_stacked = all_anomalies_stacked.reset_index('time', drop=True)\n",
    "    all_anomalies_stacked = all_anomalies_stacked.transpose('time', 'lat', 'lon')\n",
    "\n",
    "    #basically weighting so that each grid cell has influence actually proportional to its area\n",
    "    coslat = np.cos(np.deg2rad(all_anomalies_stacked.coords['lat'].values)).clip(0., 1.)\n",
    "    wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "\n",
    "    #EOF solver\n",
    "    solver = Eof(all_anomalies_stacked, weights=wgts)\n",
    "    \n",
    "    #finding the pattern of the EOF - unitless\n",
    "    EOF_pattern = solver.eofs(neofs=mode_number+1).sel(mode=mode_number)\n",
    "        \n",
    "    #getting the EA Pattern's PC\n",
    "    #using pcscaling=1 for a normalised PC. If not normalised need to divide by the variance of PC ((pc.std(dim='time'))**2) to find the regression map.\n",
    "    pc = solver.pcs(npcs=mode_number+1, pcscaling=1).sel(mode=mode_number)\n",
    "        \n",
    "    #finding regression_map = pattern of psl anomalies regressed onto EA PC, kinda which bits of the trend link to this pattern, units of hPa/unit of PC\n",
    "    #how psl anomalies change spatially for a one-unit change in the PC\n",
    "    regression_map = (all_anomalies_stacked * pc).mean(dim='time')\n",
    "\n",
    "    #making sure that the patterns match what they should for the NAO and EA patterns (basically fixing for sign conventions to make sure physical)\n",
    "    if mode == 'NAO' and regression_map.sel(lat=50, lon=-30, method='nearest') < 0:\n",
    "        regression_map *= -1\n",
    "        pc *= -1\n",
    "\n",
    "    if mode == 'NAO' and regression_map.sel(lat=50, lon=-25, method='nearest') > 0:\n",
    "        regression_map *= -1\n",
    "        pc *= -1\n",
    "        \n",
    "    #outputting .nc files for plotting\n",
    "\n",
    "    \n",
    "    regression_map.name = 'regression_'+mode+'_djf'\n",
    "    #regression_map.to_netcdf(output_regression_map)\n",
    "    EOF_pattern.name = 'EOF_'+mode+'_djf'\n",
    "    #EOF_pattern.to_netcdf(output_EOF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f147d4f4-8bd0-47c8-ad9f-eba97e905596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions defined for calculating the projections\n",
    "def project_onto_regression(trend_raw, regression_map, trend_var, mode, e, m, period):\n",
    "    #function which will project a trend (lat,lon) in hPa onto a spatial pattern (lat,lon) hPa to get a single NAO index value\n",
    "    #will then calculate the residual (trend - mode_congruent part) and saves both the NAO congruent part and the residual\n",
    "    #in the same folder, output_file is for the NAO/EA_congruent part filename\n",
    "    #can then change the input spat pattern to calculate the projection onto other eofs, e.g. the EAP\n",
    "\n",
    "\n",
    "    if isinstance(trend_raw, xr.DataArray):\n",
    "        trend = trend_raw\n",
    "    else:\n",
    "        print('here')\n",
    "        trend = trend_raw[trend_var]\n",
    "        \n",
    "    # Weight psl data by coslat to account for grid cell area decreasing with latitude\n",
    "    weights = np.cos(np.radians(trend[\"lat\"].values))\n",
    "    weights_2d = weights[:, np.newaxis]\n",
    "\n",
    "    # weight psl (or another variable) anomalies by area of each gridcell\n",
    "    weighted_trend = trend * weights_2d\n",
    "    weighted_regression = regression_map * weights_2d\n",
    "\n",
    "    # flatten both of the fields so that they are both 1D\n",
    "    trend_flat = weighted_trend.stack(spatial=('lat','lon'))\n",
    "    regression_flat = weighted_regression.stack(spatial=('lat','lon'))\n",
    "\n",
    "    #replace any NaNs with zeros to stop any weird stuff happening\n",
    "    trend_flat = trend_flat.fillna(0)\n",
    "    regression_flat = regression_flat.fillna(0)\n",
    "\n",
    "    #Now do the dot product which is the projection\n",
    "    dot_product = (trend_flat * regression_flat).sum().item()\n",
    "\n",
    "    #calculating the index - or I guess the PC?????\n",
    "    index = dot_product / (regression_flat**2).sum().item()\n",
    "\n",
    "    #Now multiplying the pattern by the index and returning that too\n",
    "    projection = index * regression_map\n",
    "    residual = trend - projection\n",
    "    \n",
    "    projection.name = 'projection_'+mode+'_djf'\n",
    "    residual.name = 'residual_'+mode+'_djf'\n",
    "\n",
    "    output_projection = '/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/'+e+'/'+m+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_projection_'+period+'.nc'\n",
    "    output_residual = '/gws/nopw/j04/extant/users/slbennie/projection_indicies/NAtlantic_forced_trends/'+e+'/'+m+'/psl_mon_'+e+'_'+m+'_DJF_'+mode+'_residual_'+period+'.nc'\n",
    "    \n",
    "    #outputting .nc files for plotting\n",
    "    projection.to_netcdf(output_projection)\n",
    "    residual.to_netcdf(output_residual)\n",
    "    \n",
    "    return projection, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7d4b2-fd09-4502-92f1-dd480c6b08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the regression map for model: CanESM5\n",
      "['/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r10i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r10i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r11i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r11i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r12i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r12i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r13i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r13i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r14i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r14i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r15i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r15i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r16i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r16i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r17i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r17i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r18i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r18i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r19i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r19i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r1i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r1i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r20i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r20i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r21i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r21i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r22i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r22i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r23i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r23i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r24i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r24i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r25i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r25i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r26i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r27i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r28i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r29i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r2i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r2i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r30i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r31i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r32i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r33i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r34i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r35i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r36i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r37i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r38i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r39i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r3i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r3i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r40i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r4i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r4i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r5i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r5i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r6i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r6i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r7i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r7i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r8i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r8i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r9i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r9i1p2f1_DJF_anomaly.nc']\n",
      "['/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r10i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r10i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r11i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r11i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r12i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r12i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r13i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r13i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r14i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r14i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r15i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r15i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r16i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r16i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r17i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r17i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r18i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r18i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r19i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r19i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r1i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r1i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r20i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r20i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r21i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r21i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r22i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r22i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r23i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r23i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r24i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r24i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r25i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r25i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r26i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r27i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r28i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r29i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r2i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r2i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r30i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r31i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r32i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r33i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r34i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r35i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r36i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r37i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r38i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r39i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r3i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r3i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r40i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r4i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r4i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r5i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r5i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r6i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r6i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r7i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r7i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r8i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r8i1p2f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r9i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/CanESM5/psl_mon_historical_CanESM5_r9i1p2f1_DJF_anomaly.nc']\n",
      "('ensemble', 'year', 'lat', 'lon')\n"
     ]
    }
   ],
   "source": [
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol','hist-totalO3','hist-volc']\n",
    "model = ['CanESM5']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for m in model:\n",
    "    #REGRESSION MAPS\n",
    "    print('Calculating the regression map for model:', m)\n",
    "    #path to the folder containing historical experiment and model's psl anomalies (calculated seperatley)\n",
    "    folder_path = f'{home}psl_anomalies/historical/{m}/'\n",
    "\n",
    "    #creating the list of files for this experiment and model's psl anomalies\n",
    "    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "    print(ens_files)\n",
    "\n",
    "    calculate_regression_map(ens_files, 'NAO', 'historical', m, period)\n",
    "    calculate_regression_map(ens_files, 'EA', 'historical', m, period)\n",
    "\n",
    "    #opening historical regression maps for use later - one per model. Use historical for all experiments.\n",
    "    regression_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_regression_map_'+period+'.nc')\n",
    "    regression_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_regression_map_'+period+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe51bc5a-c5ad-43ad-b610-21af2aba7462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the regression map for model: NorESM2-LM\n",
      "['/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r10i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r11i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r12i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r13i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r14i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r15i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r16i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r17i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r18i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r19i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r1i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r1i1p4f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r20i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r21i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r22i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r23i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r24i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r25i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r26i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r27i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r28i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r29i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r2i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r30i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r31i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r32i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r33i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r34i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r35i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r36i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r37i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r38i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r39i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r3i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r40i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r41i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r42i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r43i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r4i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r5i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r6i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r7i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r8i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r9i1p1f1_DJF_anomaly.nc']\n",
      "['/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r10i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r11i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r12i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r13i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r14i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r15i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r16i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r17i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r18i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r19i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r1i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r1i1p4f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r20i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r21i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r22i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r23i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r24i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r25i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r26i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r27i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r28i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r29i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r2i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r30i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r31i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r32i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r33i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r34i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r35i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r36i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r37i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r38i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r39i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r3i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r40i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r41i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r42i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r43i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r4i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r5i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r6i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r7i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r8i1p1f1_DJF_anomaly.nc', '/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/NorESM2-LM/psl_mon_historical_NorESM2-LM_r9i1p1f1_DJF_anomaly.nc']\n",
      "('ensemble', 'year', 'lat', 'lon')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input data is missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m ens_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path) \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m filename \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_EM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filename]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(ens_files)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mcalculate_regression_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mens_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNAO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhistorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m calculate_regression_map(ens_files, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;124m'\u001b[39m, m, period)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#opening historical regression maps for use later - one per model. Use historical for all experiments.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 35\u001b[0m, in \u001b[0;36mcalculate_regression_map\u001b[0;34m(anomalies, mode, e, m, period)\u001b[0m\n\u001b[1;32m     32\u001b[0m wgts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(coslat)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#EOF solver\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m solver \u001b[38;5;241m=\u001b[39m \u001b[43mEof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_anomalies_stacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwgts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#finding the pattern of the EOF - unitless\u001b[39;00m\n\u001b[1;32m     38\u001b[0m EOF_pattern \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39meofs(neofs\u001b[38;5;241m=\u001b[39mmode_number\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msel(mode\u001b[38;5;241m=\u001b[39mmode_number)\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/eofs/xarray.py:130\u001b[0m, in \u001b[0;36mEof.__init__\u001b[0;34m(self, array, weights, center, ddof)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Construct the EOF solver.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solver \u001b[38;5;241m=\u001b[39m \u001b[43mstandard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEof\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwtarray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Name of the input DataArray.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/eofs/standard.py:163\u001b[0m, in \u001b[0;36mEof.__init__\u001b[0;34m(self, dataset, weights, center, ddof)\u001b[0m\n\u001b[1;32m    161\u001b[0m dataNoMissing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[:, nonMissingIndex]\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataNoMissing\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input data is missing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Compute the singular value decomposition of the design matrix.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: all input data is missing"
     ]
    }
   ],
   "source": [
    "#notes find a way to update period so its nicer.\n",
    "#also could fix folder so that I use like a home dir etc.\n",
    "#anomalies have already been calculated separetly for each model so preusming they are all correct this should run?...\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol','hist-totalO3','hist-volc']\n",
    "model = ['NorESM2-LM']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for m in model:\n",
    "    #REGRESSION MAPS\n",
    "    print('Calculating the regression map for model:', m)\n",
    "    #path to the folder containing historical experiment and model's psl anomalies (calculated seperatley)\n",
    "    folder_path = f'{home}psl_anomalies/historical/{m}/'\n",
    "\n",
    "    #creating the list of files for this experiment and model's psl anomalies\n",
    "    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "    print(ens_files)\n",
    "\n",
    "    calculate_regression_map(ens_files, 'NAO', 'historical', m, period)\n",
    "    calculate_regression_map(ens_files, 'EA', 'historical', m, period)\n",
    "\n",
    "    #opening historical regression maps for use later - one per model. Use historical for all experiments.\n",
    "    regression_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_regression_map_'+period+'.nc')\n",
    "    regression_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_regression_map_'+period+'.nc')\n",
    "\n",
    "    \n",
    "    for e in experiments:\n",
    "        #ENSEMBLE MEANS\n",
    "        print('Calculating the spatial ensemble means and trends for model:', m)\n",
    "        print('Experiment:', e)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        ens_mean_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        ens_mean_djf_file = ens_mean_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, ens_mean_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(ens_mean_file, variable, seas, ens_mean_djf_file, 1850, 2015)\n",
    "\n",
    "\n",
    "        #LINEAR TREND\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "\n",
    "        #selecting file with the correct seas and period\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        print(file_path, ens_mean_djf_file)\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n",
    "\n",
    "\n",
    "        #PROJECTION\n",
    "        print(\"Calculating the projection of the forced trend onto historical regression map calculated from all ensembles:\", e)\n",
    "        \n",
    "        #now setting up the folder path to get the file names for each experiment's model's forced response's trend\n",
    "        folder_path = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'\n",
    "            \n",
    "        #Getting the list of file names within the models folder, should only be one trend per model (working off the ensemble means for each model)\n",
    "        ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and period in filename]\n",
    "        print(ens_files[0], len(ens_files), output_file)\n",
    "            \n",
    "        for i in range(0,len(ens_files)):\n",
    "            #cropping each trend to just the NA sector and whichever time\n",
    "            trend = open_cropNA_unitshPA(ens_files[i])#, 1850,2014)\n",
    "    \n",
    "            #multiplying the trend by 165 to convert to units of hPa (currently in units of hPa/year, trend calculated between 1850-2015)\n",
    "            trend = trend * 165\n",
    "\n",
    "            #calling the projection functions\n",
    "            proj_NAO, residual_NAO = project_onto_regression(trend, regression_NAO['regression_NAO_djf'], 'slope', 'NAO', e, m, period)\n",
    "            proj_EA, residual_EA = project_onto_regression(residual_NAO, regression_EA['regression_EA_djf'], 'slope', 'EA', e, m, period)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b19a671-b5a6-4c36-a85a-5de458e5a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the spatial ensemble means and trends for experiment e: historical\n",
      "Model:  NorESM2-LM\n",
      "Calculating the ensemble mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f7c86fe0290>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/jaspy/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/api.py:1369\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m writer, store\n\u001b[0;32m-> 1369\u001b[0m writes \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, BytesIO):\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/common.py:267\u001b[0m, in \u001b[0;36mArrayWriter.sync\u001b[0;34m(self, compute, chunkmanager_store_kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     chunkmanager_store_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 267\u001b[0m delayed_store \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchunkmanager_store_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/namedarray/daskmanager.py:249\u001b[0m, in \u001b[0;36mDaskManager.store\u001b[0;34m(self, sources, targets, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m store\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/dask/array/core.py:1229\u001b[0m, in \u001b[0;36mstore\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1228\u001b[0m store_dsk \u001b[38;5;241m=\u001b[39m HighLevelGraph(layers, dependencies)\n\u001b[0;32m-> 1229\u001b[0m \u001b[43mcompute_as_if_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_dsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/dask/base.py:403\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[0;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m dsk2 \u001b[38;5;241m=\u001b[39m optimization_function(\u001b[38;5;28mcls\u001b[39m)(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/dask/threaded.py:90\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 90\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/dask/local.py:501\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m fire_tasks(chunksize)\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed:\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/dask/local.py:138\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqueue_get\u001b[39m(q):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#find spatial mean across the ensembles\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating the ensemble mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mcalculate_spatial_ensemble_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#To use once spatial ensemble mean is calculated\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating the seasonal \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mseas\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m spatial ensemble mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mcalculate_spatial_ensemble_mean\u001b[0;34m(file_paths, output_file, variable)\u001b[0m\n\u001b[1;32m      9\u001b[0m mean \u001b[38;5;241m=\u001b[39m ds[variable]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#save the ensemble mean to the a .nc file\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m ds\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/core/dataarray.py:4139\u001b[0m, in \u001b[0;36mDataArray.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   4135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4136\u001b[0m     \u001b[38;5;66;03m# No problems with the name - so we're fine!\u001b[39;00m\n\u001b[1;32m   4137\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dataset()\n\u001b[0;32m-> 4139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   4140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4147\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4150\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/api.py:1376\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multifile \u001b[38;5;129;01mand\u001b[39;00m compute:\n\u001b[0;32m-> 1376\u001b[0m         \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compute:\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:577\u001b[0m, in \u001b[0;36mNetCDF4DataStore.close\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jaspy/lib/python3.11/site-packages/xarray/backends/file_manager.py:234\u001b[0m, in \u001b[0;36mCachingFileManager.close\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    232\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key, default)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#notes find a way to update period so its nicer.\n",
    "#also could fix folder so that I use like a home dir etc.\n",
    "#anomalies have already been calculated separetly for each model so preusming they are all correct this should run?...\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol','hist-totalO3','hist-volc']\n",
    "model = ['NorESM2-LM']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for e in experiment:\n",
    "    print('Calculating the spatial ensemble means and trends for experiment e:', e)\n",
    "    for m in model:\n",
    "        print('Model: ',m)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        output_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        output_file_djf = output_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, output_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(output_file, variable, seas, output_file_djf, 1850, 2015)\n",
    "\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "\n",
    "        #choosing the djf/seas\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n",
    "\n",
    "#now creating the NAO and EA regression maps - just need historical!!\n",
    "for m in model:\n",
    "    #path to the folder containing historical experiment and model's psl anomalies (calculated seperatley)\n",
    "    folder_path = f'{home}psl_anomalies/historical/{m}/'\n",
    "\n",
    "    #creating the list of files for this experiment and model's psl anomalies\n",
    "    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "\n",
    "    calculate_regression_map(ens_files, trend, 'NAO', 'slope', 'historical', m, period)\n",
    "    calculate_regression_map(ens_files, trend, 'EA', 'slope', 'historical', m, period)\n",
    "\n",
    "#Now re-opening these maps and projecting the trends onto them\n",
    "for m in model:\n",
    "    print('Model:', m)\n",
    "    regression_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_regression_map_'+period+'.nc')\n",
    "    regression_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_regression_map_'+period+'.nc')\n",
    "\n",
    "    for e in experiment:\n",
    "        print(\"Calculating the projection of the forced trend onto historical regression map calculated from all ensembles:\", e)\n",
    "        \n",
    "        #now setting up the folder path to get the file names for each experiment's model's forced response's trend\n",
    "        folder_path = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'\n",
    "            \n",
    "        #Getting the list of file names within the models folder, should only be one trend per model (working off the ensemble means for each model)\n",
    "        ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and period in filename]\n",
    "            \n",
    "        for i in range(0,len(ens_files)):\n",
    "            #cropping each trend to just the NA sector and whichever time\n",
    "            trend = open_cropNA_unitshPA(ens_files[i])#, 1850,2014)\n",
    "    \n",
    "            #multiplying the trend by 165 to convert to units of hPa (currently in units of hPa/year, trend calculated between 1850-2015)\n",
    "            trend = trend * 165\n",
    "\n",
    "            #calling the projection functions\n",
    "            proj_NAO, residual_NAO = project_onto_regression(trend, regression_NAO['regression_NAO_djf'], 'slope', 'NAO', e, m, period)\n",
    "            proj_EA, residual_EA = project_onto_regression(residual_NAO, regression_EA['regression_EA_djf'], 'slope', 'EA', e, m, period)\n",
    "\n",
    "#print(residual_NAO, residual_EA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e556e77-fa3d-4eb6-9bde-517540fcc325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ensemble', 'year', 'lat', 'lon')\n",
      "('ensemble', 'year', 'lat', 'lon')\n",
      "Model: MPI-ESM1-2-LR\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: historical\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-aer\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-GHG\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-sol\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-totalO3\n",
      "here\n",
      "Calculating the projection of the forced trend onto historical regression map calculated from all ensembles: hist-volc\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1850-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol','hist-totalO3','hist-volc']\n",
    "model = ['MPI-ESM1-2-LR']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "\n",
    "#now creating the NAO and EA regression maps - just need historical!!\n",
    "for m in model:\n",
    "    #path to the folder containing historical experiment and model's psl anomalies (calculated seperatley)\n",
    "    folder_path = f'{home}psl_anomalies/historical/{m}/'\n",
    "\n",
    "    #creating the list of files for this experiment and model's psl anomalies\n",
    "    ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and '_EM' not in filename]\n",
    "\n",
    "    calculate_regression_map(ens_files, 'NAO', 'historical', m, period)\n",
    "    calculate_regression_map(ens_files, 'EA', 'historical', m, period)\n",
    "\n",
    "#Now re-opening these maps and projecting the trends onto them\n",
    "for m in model:\n",
    "    print('Model:', m)\n",
    "    regression_NAO = xr.open_dataset(home+'regression_patterns/NAO/'+variable+'_mon_historical_'+m+'_'+seas+'_NAO_regression_map_'+period+'.nc')\n",
    "    regression_EA = xr.open_dataset(home+'regression_patterns/EA/'+variable+'_mon_historical_'+m+'_'+seas+'_EA_regression_map_'+period+'.nc')\n",
    "\n",
    "    for e in experiment:\n",
    "        print(\"Calculating the projection of the forced trend onto historical regression map calculated from all ensembles:\", e)\n",
    "        \n",
    "        #now setting up the folder path to get the file names for each experiment's model's forced response's trend\n",
    "        folder_path = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'\n",
    "            \n",
    "        #Getting the list of file names within the models folder, should only be one trend per model (working off the ensemble means for each model)\n",
    "        ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if m in filename and period in filename]\n",
    "            \n",
    "        for i in range(0,len(ens_files)):\n",
    "            #cropping each trend to just the NA sector and whichever time\n",
    "            trend = open_cropNA_unitshPA(ens_files[i])#, 1850,2014)\n",
    "    \n",
    "            #multiplying the trend by 165 to convert to units of hPa (currently in units of hPa/year, trend calculated between 1850-2015)\n",
    "            trend = trend * 165\n",
    "\n",
    "            #calling the projection functions\n",
    "            proj_NAO, residual_NAO = project_onto_regression(trend, regression_NAO['regression_NAO_djf'], 'slope', 'NAO', e, m, period)\n",
    "            proj_EA, residual_EA = project_onto_regression(residual_NAO, regression_EA['regression_EA_djf'], 'slope', 'EA', e, m, period)\n",
    "\n",
    "#print(residual_NAO, residual_EA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fbbf5ad-fd17-4a66-9cef-a716a0c0f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the spatial ensemble means and trends for experiment e: historical\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-aer\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-GHG\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n",
      "Calculating the spatial ensemble means and trends for experiment e: hist-sol\n",
      "Model:  CanESM5\n",
      "Calculating the ensemble mean\n",
      "saved\n",
      "Calculating the seasonal DJF spatial ensemble mean\n",
      "in function\n",
      "saved file\n"
     ]
    }
   ],
   "source": [
    "#had to re-do these ones for the means.\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "\n",
    "\n",
    "variable = 'psl'\n",
    "period = '1950-2015'\n",
    "experiment = ['historical', 'hist-aer', 'hist-GHG', 'hist-sol']\n",
    "model = ['CanESM5']\n",
    "modes = ['NAO', 'EA']\n",
    "seas = 'DJF'\n",
    "\n",
    "for e in experiment:\n",
    "    print('Calculating the spatial ensemble means and trends for experiment e:', e)\n",
    "    for m in model:\n",
    "        print('Model: ',m)\n",
    "        #getting the LESFMIP file paths\n",
    "        folder_path = '/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/'+e+'/'+m+'/'\n",
    "        file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if e in filename and m in filename]\n",
    "\n",
    "        #creating output files for the mean across ensembles and the djf mean\n",
    "        output_file = home+'ens_mean_spat/psl/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_spatial_EM.nc'\n",
    "        output_file_djf = output_file.replace('spatial_EM', 'spatial_'+seas+'_EM_'+period)\n",
    "        \n",
    "        #find spatial mean across the ensembles\n",
    "        print('Calculating the ensemble mean')\n",
    "        calculate_spatial_ensemble_mean(file_paths, output_file, variable)\n",
    "\n",
    "        #To use once spatial ensemble mean is calculated\n",
    "        print('Calculating the seasonal '+seas+' spatial ensemble mean')\n",
    "        calculate_seasonal_spatial_ensemble_mean_djf(output_file, variable, seas, output_file_djf, 1850, 2015)\n",
    "\n",
    "        #find the file for the ensemble spatial mean djf\n",
    "        folder_path = home+'ens_mean_spat/psl/'+e+'/'+m+'/'\n",
    "        file_path = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if seas in filename and period in filename][0]\n",
    "        output_file = home+'trend_calc_LESFMIP/linear_regression/NAO/'+e+'/'+m+'/'+variable+'_mon_'+e+'_'+m+'_'+seas+'_linear_trend_'+period+'_stats.nc'\n",
    "    \n",
    "        calculate_linear_trend_spat_pattern(file_path, variable, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956da97-e2e1-43b7-be02-56eb92b971ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
