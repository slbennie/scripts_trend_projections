{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efa2fbc-fdcb-415b-a4db-31207da0302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import re\n",
    "import cftime\n",
    "from datetime import datetime\n",
    "from dask.diagnostics import ProgressBar\n",
    "from scipy.stats import t\n",
    "from scipy.stats import linregress\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe70287-dfc8-430f-8b95-1d76956ee036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleMemberCalculations:\n",
    "    def __init__(self, data_path: Path, model=None):\n",
    "        #use self. to access attributes\n",
    "        self.data_path = Path(data_path)\n",
    "        \n",
    "        #referencing the parent model\n",
    "        self.model = model\n",
    "        self.experiment = model.experiment if model is not None else None\n",
    "\n",
    "        #extracting the member_id (ensemble number) from the filename as named in CMIP6 convention\n",
    "        match = re.search(r\"(r\\d+i\\d+p\\d+f\\d+)\", self.data_path.stem)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not extract the member_id from filenmae: {self.data_path.name}\")\n",
    "\n",
    "        #selecting the ensemble number and assigning it to the member ID\n",
    "        self.member_id = match.group(1)\n",
    "\n",
    "\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        #loads the data of an ensemble member\n",
    "        self.data = xr.open_dataset(self.data_path)\n",
    "        return self.data\n",
    "\n",
    "    def get_calendar_type(self):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model is not set\")\n",
    "        return self.model.calendar_type\n",
    "\n",
    "    def get_time_bounds(self):\n",
    "        \"\"\"\n",
    "        Access the model's time_bounds - each model has a different calendar thus type of time to index/slice by\n",
    "        \"\"\"\n",
    "        if self.model is None or self.model.time_bounds is None:\n",
    "            raise RuntimeError(\"Model or time_bounds is not set\")\n",
    "        return self.model.time_bounds\n",
    "\n",
    "    def select_data(self, varname: str):\n",
    "        \"\"\"\n",
    "        Just selecting some data from the time bounds in model\n",
    "        \"\"\"\n",
    "        ds = self.load_data()\n",
    "        start, end, delta = self.model.time_bounds\n",
    "        ds = ds[varname].sel(time=slice(start, end))\n",
    "        \n",
    "        return ds\n",
    "\n",
    "    def crop_to_domain_ensemble(self, da: xr.DataArray):\n",
    "        \"\"\"\n",
    "        Crops the ensemble members data (anomaly, raw data etc.) to the lat and lon of the domain\n",
    "        lat_bounds = (lat_min, lat_max)\n",
    "        lon_bounds = (lon_min, lon_max)\n",
    "        Assuming data of the format -180 to 180, -90 to 90???\n",
    "        Will add another function to check and if not flag error\n",
    "        Will be a bit for if model is era5 shift the coords at somepoint in the processing data stages.\n",
    "        Need to already have selected the variable\"\"\"\n",
    "\n",
    "        if self.experiment and self.experiment.lat_bounds and self.experiment.lon_bounds:\n",
    "            da = da.sel(\n",
    "                lat=slice(self.experiment.lat_bounds[0], self.experiment.lat_bounds[1]),\n",
    "                lon = slice(self.experiment.lon_bounds[0], self.experiment.lon_bounds[1])\n",
    "            )\n",
    "        return da\n",
    "\n",
    "    def calc_anomaly(self, output_file: Path, varname: str):\n",
    "        \"\"\"\n",
    "        Will calculate the anomaly\n",
    "        \"\"\"\n",
    "        #print(output_file)\n",
    "        print(self.model.name)\n",
    "        if output_file.exists():\n",
    "            #print(f\"Loading the exisiting file for the anomaly from: {output_file}\")\n",
    "            anomaly = xr.open_dataset(output_file)[varname]\n",
    "            anomaly_cropped = self.crop_to_domain_ensemble(anomaly)\n",
    "            return anomaly_cropped\n",
    "\n",
    "   # def cal_seasonal_mean(self)\n",
    "\n",
    "        \n",
    "\n",
    "class ModelCalculations:\n",
    "    def __init__(self, folder: Path, experiment):\n",
    "        self.folder = Path(folder)\n",
    "        self.experiment = experiment\n",
    "\n",
    "        #can now set the model name using the folder name\n",
    "        #the .name takes the last bit of the filepath (which in this case is the model)\n",
    "        self.name = self.folder.name\n",
    "        print(f\"Model name set to {self.name}\")\n",
    "\n",
    "        #creating my dictionary of ensemble members\n",
    "        self.members = {}\n",
    "        for i, file in enumerate(self.folder.glob(\"*.nc\")):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            member = EnsembleMemberCalculations(file, model=self)\n",
    "            self.members[member.member_id] = member\n",
    "        \n",
    "        #basically I pick the first member (load in just one)\n",
    "        #doing this to then use to find the calendar type\n",
    "        #and then find the time bounds as this will be the same time (correct datetime) per model\n",
    "        member1 = next(iter(self.members.values()))\n",
    "        member1.load_data()\n",
    "\n",
    "        #find the calendar type\n",
    "        time_var = member1.data[\"time\"]\n",
    "        self.calendar_type = type(time_var.time.values[0])\n",
    "        self.time_bounds = None\n",
    "\n",
    "    def set_time_bounds(self, start_year: int, end_year: int):\n",
    "        #selecting the correct datetime format for the chosen time period\n",
    "        print(self.calendar_type)\n",
    "        if issubclass(self.calendar_type, cftime.DatetimeNoLeap):\n",
    "            start = cftime.DatetimeNoLeap(start_year,1,16)\n",
    "            end = cftime.DatetimeNoLeap(end_year,12,16)\n",
    "        elif issubclass(self.calendar_type, cftime.Datetime360Day):\n",
    "            start = cftime.Datetime360Day(start_year,1,16)\n",
    "            end = cftime.Datetime360Day(end_year,12,16)\n",
    "        else:\n",
    "            start = datetime(start_year,1,16)\n",
    "            end = datetime(end_year,12,16)\n",
    "\n",
    "        #assumes that the last year is filled with data\n",
    "        delta = end.year - start.year + 1\n",
    "\n",
    "        self.time_bounds = (start, end, delta)\n",
    "        print(self.time_bounds)\n",
    "        return self.time_bounds\n",
    "\n",
    "    def crop_to_domain_model(self, da: xr.DataArray):\n",
    "        \"\"\"\n",
    "        Crops the ensemble members data (anomaly, raw data etc.) to the lat and lon of the domain\n",
    "        lat_bounds = (lat_min, lat_max)\n",
    "        lon_bounds = (lon_min, lon_max)\n",
    "        Assuming data of the format -180 to 180, -90 to 90???\n",
    "        Will add another function to check and if not flag error\n",
    "        Will be a bit for if model is era5 shift the coords at somepoint in the processing data stages.\n",
    "        Need to already have selected the variable\"\"\"\n",
    "\n",
    "        if self.experiment and self.experiment.lat_bounds and self.experiment.lon_bounds:\n",
    "            da = da.sel(\n",
    "                lat=slice(self.experiment.lat_bounds[0], self.experiment.lat_bounds[1]),\n",
    "                lon = slice(self.experiment.lon_bounds[0], self.experiment.lon_bounds[1])\n",
    "            )\n",
    "        return da\n",
    "\n",
    "\n",
    "    def calc_ensemble_mean(self, varname: str):\n",
    "        \"\"\"\n",
    "        Calculate the SPATIAL ensemble mean for a variable\n",
    "        Restrict it to the time bounds\n",
    "        Could in future restrict to an area\n",
    "        If the file exists load this instead\n",
    "        \"\"\"\n",
    "        output_file = self.experiment.output_dir / f\"ens_mean_spat/{model_name}/{varname}_mon_{self.name}_{model_name}_spatial_DJF_EM_1850-2015.nc\"\n",
    "        \n",
    "        if output_file.exists():\n",
    "            print(f\"Loading the exisiting file for the spatial ensemble mean from: {output_file}\")\n",
    "            ens_mean = xr.open_dataset(output_file)[varname]\n",
    "            return ens_mean\n",
    "        \n",
    "        #Get all the filepaths from the ensemble members\n",
    "        #this line basically is getting the filepaths of the ensemble member class objects - i think?\n",
    "        file_paths = [member.data_path for member in self.members.values()]\n",
    "\n",
    "        #then opening them all together\n",
    "        ds = xr.open_mfdataset(\n",
    "            file_paths,\n",
    "            combine=\"nested\",\n",
    "            concat_dim=\"member\",\n",
    "            parallel=True,\n",
    "            chunks={\"member\": 1}\n",
    "        )[varname]\n",
    "\n",
    "        #selecting the time period\n",
    "        start,end, delta = self.time_bounds\n",
    "        ds = ds.sel(time=slice(start,end))\n",
    "\n",
    "        #calculating the ensemble mean across the members\n",
    "        ens_mean = ds.mean(dim=\"member\")\n",
    "    \n",
    "        # Compute the result with a progress bar\n",
    "        print(f\"Computing the ensemble mean for {self.name}...\")\n",
    "        with ProgressBar():\n",
    "            ens_mean.compute()#.to_netcdf(output_file)\n",
    "\n",
    "        ens_mean.to_netcdf(output_file)\n",
    "        print(f'Ensemble mean NOT saved to {output_file}')\n",
    "\n",
    "        return ens_mean\n",
    "\n",
    "    def calc_seasonal_mean_per_model(self, varname:str):\n",
    "        \"\"\"\n",
    "        Calculating the seasonal ensemble mean (could actually just be the seasonal mean for ay single file!!!)\n",
    "        Only accpeting one file so per model\n",
    "        Will save the seasonal mean as well as outputting it\n",
    "        Wil crop to the already saved time periods.\n",
    "        Will at some point make more versatille to choose the months of the year etc. as a list of int.\n",
    "        \"\"\"\n",
    "\n",
    "        #select the time bounds and seasons\n",
    "        start,end = self.time_bounds\n",
    "        print(start,end)\n",
    "        months = self.experiment.season\n",
    "        season = \"\".join([calendar.month_abbr[m][0] for m in months])\n",
    "        print(months, season)\n",
    "        \n",
    "        seas_EM_output_file = self.experiment.output_dir / f\"ens_mean_spat/{self.experiment.name}/{self.name}/psl_mon_{self.experiment.name}_{self.name}_spatial_{season}_EM_1850-2015.nc\"\n",
    "        \n",
    "        if seas_EM_output_file.exists():\n",
    "            print(f\"Loading the seasonal mean for model: {self.name}\")\n",
    "            seasonal_mean = xr.open_dataset(seas_EM_output_file)[varname]\n",
    "            return seasonal_mean\n",
    "\n",
    "        #loading the ensemble mean\n",
    "        ens_mean = self.calc_ensemble_mean(varname)\n",
    "\n",
    "        #checking it is a datetime object - already done???\n",
    "        #ens_mean['time'] = xr.decode(ens_mean).time\n",
    "\n",
    "        #selecting the ensemble mean for the specified time (might load full ensemble mean as this is already calculated and then slice here)\n",
    "        ens_mean = ens_mean.sel(time=slice(start,end))\n",
    "\n",
    "        #creating mask for the season and grouping the months\n",
    "        mask = ens_mean['time'].dt.month.isin(months)\n",
    "        months_in_seas = ens_mean.sel(time=mask)\n",
    "\n",
    "        #assigning a 'season year'\n",
    "        season_year = months_in_seas['time'].dt.year\n",
    "\n",
    "        #general code for if season WRAPS then fix the year to avg over\n",
    "        if months[0] > months[-1]:\n",
    "            season_year = xr.where(months_in_seas['time'].dt.month >= months[0],\n",
    "                                  season_year +1,\n",
    "                                  season_year)\n",
    "\n",
    "        #assign as \"year\" instead of \"season_year\" for future bits\n",
    "        months_in_seas = months_in_seas.assign_coords(year=season_year)\n",
    "        \n",
    "        #now groupby and average over the years\n",
    "        ens_mean_seas = months_in_seas.groupby('year').mean(dim='time')\n",
    "        #ens_mean_seas.to_netcdf(seas_EM_output_file)\n",
    "\n",
    "        print('calc seas_mean')\n",
    "        \n",
    "        return ens_mean_seas\n",
    "\n",
    "    def calc_linear_trend_per_model(self, varname:str):\n",
    "        \"\"\"\n",
    "        Calcualte the linear trend from the seasonal ensemble mean\n",
    "        Full stats file\"\"\"\n",
    "        #getting the timebounds\n",
    "        start,end, delta = self.time_bounds\n",
    "             \n",
    "        #create and check if output_file exists\n",
    "        output_file = self.experiment.output_dir / f\"trend_calc_LESFMIP/linear_regression/NAO/{self.experiment.name}/{self.name}/psl_mon_{self.experiment.name}_{self.name}_DJF_linear_trend_1850-2015_stats.nc\"\n",
    "\n",
    "        if output_file.exists():\n",
    "            print(f\"loading the linear trend for model: {self.name}\")\n",
    "            return xr.open_dataset(output_file)\n",
    "            \n",
    "        #call the seasonal ensemble mean method\n",
    "        seas_ens_mean = self.calc_seasonal_mean_per_model(varname)\n",
    "        print(seas_ens_mean)\n",
    "    \n",
    "        time = seas_ens_mean['year'].values\n",
    "        lat = seas_ens_mean['lat'].values\n",
    "        lon = seas_ens_mean['lon'].values\n",
    "        time_numeric = np.arange(len(time))\n",
    "    \n",
    "        slope = np.full((len(lat), len(lon)), np.nan)\n",
    "        intercept = np.full((len(lat), len(lon)), np.nan)\n",
    "        p_value = np.full((len(lat), len(lon)), np.nan)\n",
    "        stderr = np.full((len(lat), len(lon)), np.nan)\n",
    "\n",
    "        #now solving for the slope and other stats (multiplying through by delta to convert from per index\n",
    "        #(year) to change over the entire period)\n",
    "        for i in range(len(lat)):\n",
    "            for j in range(len(lon)):\n",
    "                ts = seas_ens_mean[:, i, j].values\n",
    "                if np.all(np.isfinite(ts)):\n",
    "                    reg = linregress(time_numeric, ts)\n",
    "                    slope[i, j] = reg.slope * delta\n",
    "                    intercept[i, j] = reg.intercept\n",
    "                    p_value[i, j] = reg.pvalue\n",
    "                    stderr[i, j] = reg.stderr * delta\n",
    "    \n",
    "        n = len(time_numeric)\n",
    "        df = n - 2\n",
    "        alpha = 0.05\n",
    "        t_crit = t.ppf(1 - alpha/2, df)\n",
    "    \n",
    "        ci_lower = slope - t_crit * stderr\n",
    "        ci_upper = slope + t_crit * stderr\n",
    "    \n",
    "        slope_da = xr.DataArray(slope, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope\")\n",
    "        intercept_da = xr.DataArray(intercept, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"intercept\")\n",
    "        p_value_da = xr.DataArray(p_value, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"p_value\")\n",
    "        ci_lower_da = xr.DataArray(ci_lower, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_lower\")\n",
    "        ci_upper_da = xr.DataArray(ci_upper, coords=[lat, lon], dims=[\"lat\", \"lon\"], name=\"slope_CI_upper\")\n",
    "    \n",
    "        # Save to one combined netCDF file\n",
    "        trend_stats = xr.Dataset({\n",
    "            \"slope\": slope_da,\n",
    "            \"intercept\": intercept_da,\n",
    "            \"p_value\": p_value_da,\n",
    "            \"slope_CI_lower\": ci_lower_da,\n",
    "            \"slope_CI_upper\": ci_upper_da\n",
    "        })\n",
    "        \n",
    "        #combined_ds.to_netcdf(output_file)\n",
    "        return trend_stats\n",
    "\n",
    "    def calc_anomalies_all_members(self, varname: str,):\n",
    "        \"\"\"\n",
    "        This will calculate the anomaly across the ensemble members\n",
    "        Could maybe do this for all the other individual ensemble calcs needed to calc anomaly?\n",
    "        Will return a dictionary {member_id: anomaly_dataarray}\n",
    "        Only calculates for the hisotircal??? - no need it for all!\"\"\"\n",
    "\n",
    "        self.experiment.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results = {}\n",
    "        for member_id, member in self.members.items():\n",
    "            output_file = self.experiment.output_dir / f\"psl_anomalies/{self.experiment.name}/{self.name}/psl_mon_{self.experiment.name}_{self.name}_{member_id}_DJF_anomaly.nc\"\n",
    "            anomaly = member.calc_anomaly(output_file, varname)\n",
    "            results[member_id] = anomaly\n",
    "        return results\n",
    "\n",
    "    def calc_EOF_concat(self, varname: str, max_modes: int):\n",
    "        \"\"\"\n",
    "        Calculates the EOF from a concatenated list of anomalies for one model\n",
    "        outputs the number of modes specified\n",
    "        Calls on the anomalies calculated for each ensemble member\n",
    "        This right now does all models not just historical - need an option for that somewhere???\n",
    "        \"\"\"\n",
    "        output_file = self.experiment.output_dir / f\"{self.experiment.name}/{self.name}/psl_mon_{self.experiment.name}_{self.name}_DJF_EOF_concat_1850-2015.nc\"\n",
    "\n",
    "        if output_file.exists():\n",
    "            print(f\"Loading the exisiting file for the EOF for: {output_file}\")\n",
    "            EOF = xr.open_dataset(output_file)[varname]\n",
    "            return EOF\n",
    "\n",
    "\n",
    "        else:\n",
    "            print('concatenating')\n",
    "            #preprocess anomalies method called\n",
    "            anomalies = self.calc_anomalies_all_members(varname)\n",
    "\n",
    "            anomaly_list = list(anomalies.values())\n",
    "            anomaly_concat = xr.concat(anomaly_list, dim=\"ensemble\")\n",
    "            anomaly_2d = anomaly_concat.stack(time=('ensemble', 'year')).reset_index('time', drop=True)\n",
    "            anomaly_trans = anomaly_2d.transpose('time', 'lat', 'lon')\n",
    "            \n",
    "            coslat = np.cos(np.deg2rad(anomaly_trans.coords['lat'].values)).clip(0., 1.)\n",
    "            wgts = np.sqrt(coslat)[...,np.newaxis]\n",
    "\n",
    "            solver = Eof(anomaly_trans, weights=wgts)\n",
    "            EOF = solver.eofs(neofs=max_modes).sel(mode=([0,max_modes-1]))\n",
    "\n",
    "            #checking orthogonality\n",
    "            #1. Get the first two PCs (time series of each mode)\n",
    "            pcs = solver.pcs(npcs=2, pcscaling=0)  # shape (time, mode)\n",
    "    \n",
    "            # 2. Compute their correlation / covariance\n",
    "            pc_corr = np.corrcoef(pcs[:, 0], pcs[:, 1])[0, 1]\n",
    "            print(\"Correlation between PC1 and PC2:\", pc_corr)\n",
    "\n",
    "            # 3. (Optional) Gram matrix of PCs\n",
    "            G = np.dot(pcs.T, pcs)  # shape (2,2)\n",
    "            print(\"Gram matrix of PCs:\\n\", G)\n",
    "\n",
    "            #Check orthogonality\n",
    "            EOF1 = EOF.sel(mode=0)\n",
    "            EOF2 = EOF.sel(mode=1)\n",
    "    \n",
    "            inner = (EOF1 * EOF2).sum(dim=(\"lat\", \"lon\"))\n",
    "            norm1 = np.sqrt((EOF1**2).sum(dim=(\"lat\", \"lon\")))\n",
    "            norm2 = np.sqrt((EOF2**2).sum(dim=(\"lat\", \"lon\")))\n",
    "            cos_sim = inner / (norm1 * norm2)\n",
    "            is_ortho = bool(np.isclose(inner, 0, atol=1e-10))\n",
    "            \n",
    "            print(f\"Inner product: {inner:.3e}, Cosine similarity: {cos_sim:.3e}\")\n",
    "            if not is_ortho:\n",
    "                print(\"⚠️ Warning: EOF1 and EOF2 are not orthogonal within tolerance!\")\n",
    "\n",
    "        \n",
    "            #EOF.to_netcdf(output_file)\n",
    "\n",
    "        return EOF\n",
    "\n",
    "    def projection(self, varname: str, max_modes):\n",
    "        #need to somehow specify that its historical EOF ONLY - but maybe still calculate for the other ones - need all anomalies???\n",
    "\n",
    "        output_file = self.experiment.output_dir / f\"regression_patterns/NAO/psl_mon_historical_HadGEM3-GC31-LL_DJF_NAO_EOF_pattern_1850-2015.nc\"\n",
    "\n",
    "        if output_file.exists():\n",
    "            print(\"loading EOF file for model:\", self.name)\n",
    "            return xr.open_dataset(output_file)\n",
    "\n",
    "        trend = self.calc_linear_trend_per_model['slope']\n",
    "        EOF = self.calc_EOF_concat['eofs']\n",
    "\n",
    "        #weighting the trend ONLY (EOF already weighted)\n",
    "        w = np.sqrt(np.cos(np.radians(trend['lat'])))\n",
    "        w2d, _ = xr.broadcast(w, trend)\n",
    "\n",
    "        #stacking the trend and EOF \n",
    "        trend_w = (trend * w2d).stack(spatial=('lat','lon')).values\n",
    "        EOF = (EOF).stack(spatial=('lat','lon')).values #lat,lon,mode\n",
    "\n",
    "        #transpose for the lstsq\n",
    "        E_matrix = EOF.T\n",
    "\n",
    "        #solve the weighted least squares\n",
    "        c = np.linalg.lstsq(E_matrix, trend_w, rcond=None)[0]\n",
    "\n",
    "        #reconstruct the coefficients\n",
    "        #got to here need to figure out how to extract???\n",
    "        #for i in range(0, max_modes) vibes then extract and just save\n",
    "        #somehow return??? need to think more about the format\n",
    "\n",
    "        return ('this')\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "class ExperimentCalculations:\n",
    "    def __init__(self, folder: Path, output_dir: Path):\n",
    "        \"\"\"\n",
    "        Initialise an experiment object\n",
    "        Each folder inside this experiment is a model\n",
    "        \"\"\"\n",
    "        self.folder = Path(folder)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        #the experiment name (resturns the last part of the name!!!)\n",
    "        self.name = self.folder.name\n",
    "\n",
    "        #this is the dictionary of ModelCalculations objects\n",
    "        self.models = {}\n",
    "\n",
    "        #going through all the sub folders within this experiment folder\n",
    "        #The creating a ModelCalculations object for models folders\n",
    "        for model_folder in self.folder.iterdir():\n",
    "            if model_folder.is_dir():\n",
    "                model = ModelCalculations(model_folder, experiment=self)\n",
    "                self.models[model.name] = model\n",
    "\n",
    "        print(f\"loaded in {len(self.models)} models for experiment '{self.folder.name}'\")\n",
    "\n",
    "        #for the domain bounds\n",
    "        self.lat_bounds = None\n",
    "        self.lon_bounds = None\n",
    "\n",
    "        self.season = None\n",
    "            \n",
    "    def set_time_bounds(self, start_year: int, end_year:int):\n",
    "        \"\"\"\n",
    "        Set the time bounds for all the models in this experiment\n",
    "        \"\"\"\n",
    "\n",
    "        for model in self.models.values():\n",
    "            model.set_time_bounds(start_year, end_year)\n",
    "\n",
    "    def set_domain(self, lat_bounds: tuple, lon_bounds: tuple):\n",
    "        \"\"\"\n",
    "        Defining the coordingates for the domain for cropping\n",
    "        \"\"\"\n",
    "\n",
    "        self.lat_bounds = lat_bounds\n",
    "        self.lon_bounds = lon_bounds\n",
    "        print(self.lat_bounds, self.lon_bounds)\n",
    "\n",
    "    def set_season(self, season: list[int]):\n",
    "        \"\"\"\n",
    "        Sets the season - list like 12,1,2 is DJF\n",
    "        \"\"\"\n",
    "\n",
    "        self.season = season\n",
    "        print(season)\n",
    "        \n",
    "    def calc_ensemble_mean_all_models(self, varname: str):\n",
    "        \"\"\"\n",
    "        Calculate the ensemble mean for each model within this experiment\n",
    "        Save results to an output dir\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            print(self.name)\n",
    "\n",
    "            ens_mean = model.calc_ensemble_mean(varname)\n",
    "            results[model_name] = ens_mean\n",
    "\n",
    "        return results\n",
    "        \n",
    "    def calc_seasonal_EM_all_models(self, varname: str):\n",
    "        \"\"\"\n",
    "        Calculate the ensemble mean for each model within this experiment\n",
    "        Save results to an output dir\n",
    "        \"\"\"\n",
    "\n",
    "        self.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            print(self.name)\n",
    "            \n",
    "            seas_ens_mean = model.calc_seasonal_mean_per_model(varname)\n",
    "            results[model_name] = seas_ens_mean\n",
    "\n",
    "        return results\n",
    "\n",
    "    def calc_linear_trend_all_models(self, varname: str):\n",
    "        \"\"\"\n",
    "        Calculate the linear trend from the seasonal ensemble mean\n",
    "        Save results to an output dir\n",
    "        \"\"\"\n",
    "\n",
    "        self.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            print(self.name)\n",
    "            \n",
    "            trend = model.calc_linear_trend_per_model(varname)\n",
    "            results[model_name] = trend\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "    def calc_anomalies_all_models(self, varname: str):\n",
    "        \"\"\"\n",
    "        Calculate the anomalies across all ensemble members and models\n",
    "        Will probably add in the steps that happen before - either call here or within calc_anomaly\n",
    "        returns a dict of dict: {model_name: {member_id: anomaly_dataset}}\n",
    "        \"\"\"\n",
    "\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            model_results = model.calc_anomalies_all_members(varname)\n",
    "            results[model_name] = model_results\n",
    "\n",
    "        return results\n",
    "\n",
    "    def calc_EOF_concat_all_models(self, varname: str, max_modes: int):\n",
    "        \"\"\"\n",
    "        To calculate the EOFs across all models\n",
    "        \"\"\"\n",
    "\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            model_results = model.calc_EOF_concat(varname, max_modes)\n",
    "            results[model_name] = model_results\n",
    "\n",
    "        return results\n",
    "\n",
    "    def projection_all_models(self, varname: str, max_modes: int):\n",
    "        \"\"\"\n",
    "        Project linear trend onto ALL modes for each model\n",
    "        \"\"\"\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results = {}\n",
    "        for model_name, model in self.models.items():\n",
    "            proj = model.projection(varname, max_modes)\n",
    "            results[model_name] = proj\n",
    "\n",
    "        return results\n",
    "        \n",
    "\n",
    "\n",
    "class Comparisons:\n",
    "    def __init__(self, folder: Path, output_dir: Path):\n",
    "        \"\"\"\n",
    "        Initialise a comparisons object\n",
    "        Will be used to comapre between all models and all experiments.\n",
    "        Pass through the folder up to the experiments - will automatically sort for the experiment available\n",
    "        \"\"\"\n",
    "        self.folder = Path(folder)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        #the experiment name (resturns the last part of the name!!!)\n",
    "\n",
    "        #this is the dictionary of ExperimentCalculations objects\n",
    "        self.experiments = {}\n",
    "\n",
    "        #going through all the sub folders within this experiment folder\n",
    "        #The creating a ModelCalculations object for models folders\n",
    "        for experiment_folder in self.folder.iterdir():\n",
    "            if experiment_folder.is_dir():\n",
    "                experiment = ExperimentCalculations(experiment_folder, output_dir)\n",
    "                self.models[model.name] = model\n",
    "\n",
    "        print(f\"loaded in {len(self.models)} models for experiment '{self.folder.name}'\")\n",
    "\n",
    "        #for the domain bounds\n",
    "        self.lat_bounds = None\n",
    "        self.lon_bounds = None\n",
    "\n",
    "        self.season = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3546341f-afcc-433a-beed-91f791f25e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name set to ACCESS-ESM1-5\n",
      "Model name set to CMCC-CM2-SR5\n",
      "Model name set to CNRM-CM6-1\n",
      "Model name set to CanESM5\n",
      "Model name set to FGOALS-g3\n",
      "Model name set to GISS-E2-1-G\n",
      "Model name set to HadGEM3-GC31-LL\n",
      "Model name set to IPSL-CM6A-LR\n",
      "Model name set to MIROC6\n",
      "Model name set to MPI-ESM1-2-LR\n",
      "Model name set to NorESM2-LM\n",
      "loaded in 11 models for experiment 'historical'\n",
      "<class 'numpy.datetime64'>\n",
      "(datetime.datetime(1850, 1, 16, 0, 0), datetime.datetime(2014, 12, 16, 0, 0), 165)\n",
      "<class 'cftime._cftime.DatetimeNoLeap'>\n",
      "(cftime.DatetimeNoLeap(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.DatetimeNoLeap(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True), 165)\n",
      "<class 'numpy.datetime64'>\n",
      "(datetime.datetime(1850, 1, 16, 0, 0), datetime.datetime(2014, 12, 16, 0, 0), 165)\n",
      "<class 'cftime._cftime.DatetimeNoLeap'>\n",
      "(cftime.DatetimeNoLeap(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.DatetimeNoLeap(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True), 165)\n",
      "<class 'cftime._cftime.DatetimeNoLeap'>\n",
      "(cftime.DatetimeNoLeap(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.DatetimeNoLeap(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True), 165)\n",
      "<class 'cftime._cftime.DatetimeNoLeap'>\n",
      "(cftime.DatetimeNoLeap(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.DatetimeNoLeap(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True), 165)\n",
      "<class 'cftime._cftime.Datetime360Day'>\n",
      "(cftime.Datetime360Day(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.Datetime360Day(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True), 165)\n",
      "<class 'numpy.datetime64'>\n",
      "(datetime.datetime(1850, 1, 16, 0, 0), datetime.datetime(2014, 12, 16, 0, 0), 165)\n",
      "<class 'numpy.datetime64'>\n",
      "(datetime.datetime(1850, 1, 16, 0, 0), datetime.datetime(2014, 12, 16, 0, 0), 165)\n",
      "<class 'numpy.datetime64'>\n",
      "(datetime.datetime(1850, 1, 16, 0, 0), datetime.datetime(2014, 12, 16, 0, 0), 165)\n",
      "<class 'cftime._cftime.DatetimeNoLeap'>\n",
      "(cftime.DatetimeNoLeap(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.DatetimeNoLeap(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True), 165)\n",
      "(20, 80) (-90, 40)\n",
      "[12, 1, 2]\n",
      "loading EOF file for model: ACCESS-ESM1-5\n",
      "loading EOF file for model: CMCC-CM2-SR5\n",
      "loading EOF file for model: CNRM-CM6-1\n",
      "loading EOF file for model: CanESM5\n",
      "loading EOF file for model: FGOALS-g3\n",
      "loading EOF file for model: GISS-E2-1-G\n",
      "loading EOF file for model: HadGEM3-GC31-LL\n",
      "loading EOF file for model: IPSL-CM6A-LR\n",
      "loading EOF file for model: MIROC6\n",
      "loading EOF file for model: MPI-ESM1-2-LR\n",
      "loading EOF file for model: NorESM2-LM\n"
     ]
    }
   ],
   "source": [
    "historical = ExperimentCalculations(Path(\"/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/historical/\"), Path(\"/gws/nopw/j04/extant/users/slbennie/\"))\n",
    "historical.set_time_bounds(1850, 2014)\n",
    "historical.set_domain(lat_bounds=(20,80), lon_bounds=(-90,40))\n",
    "historical.set_season([12,1,2])\n",
    "\n",
    "linear_trend = historical.projection_all_models(\n",
    "    varname='psl',\n",
    "    max_modes=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#historical_ens_mean = historical.calc_ensemble_mean_all_models('psl', Path(\"/gws/nopw/j04/extant/users/slbennie/ens_mean_spat/psl/historical/\"))\n",
    "\n",
    "# Compute anomalies for all ensemble members and models\n",
    "#anomaly_results = historical.calc_anomalies_all_models(\n",
    "#    varname=\"psl\",\n",
    "#    output_dir=Path(\"/gws/nopw/j04/extant/users/slbennie/psl_anomalies/historical/\")\n",
    "#)\n",
    "\n",
    "#print(anomaly_results['CanESM5']['r10i1p1f1'].values)\n",
    "\n",
    "#compute the EOF for all models\n",
    "\n",
    "#HadGEM3 = historical.models['HadGEM3-GC31-LL']\n",
    "#EOF = historical.calc_EOF_concat_all_models(\n",
    "#    output_dir = Path('/gws/nopw/j04/extant/users/slbennie/EOF/'),\n",
    "#                    varname='psl',\n",
    "#                    max_modes=2\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6ffd987-e575-41c1-ab2d-94fb69962be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'psl' (year: 165, lat: 25, lon: 53)> Size: 2MB\n",
      "[218625 values with dtype=float64]\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 200B 20.0 22.5 25.0 27.5 30.0 ... 72.5 75.0 77.5 80.0\n",
      "  * lon      (lon) float64 424B -90.0 -87.5 -85.0 -82.5 ... 32.5 35.0 37.5 40.0\n",
      "  * year     (year) int64 1kB 1850 1851 1852 1853 1854 ... 2011 2012 2013 2014\n",
      "    season   <U3 12B ...\n"
     ]
    }
   ],
   "source": [
    "print(anomaly_results['CanESM5']['r10i1p1f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62749b84-6fcd-45c3-b5c6-236f4824178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name set to HadGEM3-GC31-LL\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model.set_season('DJF')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gws/nopw/j04/extant/users/slbennie/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m seas_mean_DJF \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_seasonal_mean_per_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDJF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpsl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#ens_mean = model.calc_ensemble_mean(Path(\"/gws/nopw/j04/extant/users/slbennie/ens_mean_spat/psl/historical/HadGEM3-GC31-LL/psl_mon_historical_HadGEM3-GC31-LL_spatial_DJF_EM_1850-2015.nc\"), 'psl')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#ens_mean\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 175\u001b[0m, in \u001b[0;36mModelCalculations.calc_seasonal_mean_per_model\u001b[0;34m(self, output_dir, season, varname)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_seasonal_mean_per_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_dir: Path, season: \u001b[38;5;28mstr\u001b[39m, varname:\u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    167\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    Calculating the seasonal ensemble mean (could actually just be the seasonal mean for ay single file!!!)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    Only accpeting one file so per model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    Will at some point make more versatille to choose the months of the year etc. as a list of int.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     seas_EM_output_file \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mens_mean_spat/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/psl_mon_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_spatial_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_EM_1850-2015.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_file\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading the seasonal mean for model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "model = ModelCalculations(Path(\"/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/historical/HadGEM3-GC31-LL/\"), 'historical')\n",
    "model.set_time_bounds(1850, 2014)\n",
    "#model.set_season('DJF')\n",
    "output_dir = \"/gws/nopw/j04/extant/users/slbennie/\"\n",
    "seas_mean_DJF = model.calc_seasonal_mean_per_model(output_dir, 'DJF', 'psl')\n",
    "#ens_mean = model.calc_ensemble_mean(Path(\"/gws/nopw/j04/extant/users/slbennie/ens_mean_spat/psl/historical/HadGEM3-GC31-LL/psl_mon_historical_HadGEM3-GC31-LL_spatial_DJF_EM_1850-2015.nc\"), 'psl')\n",
    "#ens_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f65a5ea-dffa-4c8d-99cf-99a5c2cff3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cftime.Datetime360Day(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.Datetime360Day(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True))\n",
      "(cftime.Datetime360Day(1850, 1, 16, 0, 0, 0, 0, has_year_zero=True), cftime.Datetime360Day(2014, 12, 16, 0, 0, 0, 0, has_year_zero=True))\n",
      "360_day\n",
      "<xarray.DataArray 'psl' (time: 1980, lat: 71, lon: 144)> Size: 162MB\n",
      "[20243520 values with dtype=float64]\n",
      "Coordinates:\n",
      "  * time     (time) object 16kB 1850-01-16 00:00:00 ... 2014-12-16 00:00:00\n",
      "  * lat      (lat) float64 568B -87.5 -85.0 -82.5 -80.0 ... 80.0 82.5 85.0 87.5\n",
      "  * lon      (lon) float64 1kB -180.0 -177.5 -175.0 -172.5 ... 172.5 175.0 177.5\n",
      "Attributes:\n",
      "    standard_name:  air_pressure_at_mean_sea_level\n",
      "    long_name:      Sea Level Pressure\n",
      "    comment:        Sea Level Pressure\n",
      "    units:          Pa\n",
      "    original_name:  mo: (stash: m01s16i222, lbproc: 128)\n",
      "    cell_methods:   area: time: mean\n",
      "    cell_measures:  area: areacella\n",
      "Loading the exisiting file for the spatial ensemble mean from: /gws/nopw/j04/extant/users/slbennie/ens_mean_spat/psl/historical/HadGEM3-GC31-LL/psl_mon_historical_HadGEM3-GC31-LL_spatial_DJF_EM_1850-2015.nc\n"
     ]
    }
   ],
   "source": [
    "model = ModelCalculations(Path(\"/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/historical/HadGEM3-GC31-LL/\"))\n",
    "\n",
    "model.set_time_bounds(1850, 2014)\n",
    "\n",
    "member1 = next(iter(model.members.values()))\n",
    "\n",
    "#so model.members is my dictionary of ensemble members, keys are member_ids values are EnsembleMemberCalculations objects\n",
    "#\"r1i1p1f1\": <EnsembleMemberCalculations object>, ...\n",
    "#the .values() returns all the values\n",
    "#iter() lets you iterate throught the objects one by one\n",
    "#next() grabs the firt item.\n",
    "\n",
    "#EQUIVALENT\n",
    "#first_key = list(model.members.keys())[0]\n",
    "#member1 = model.members[first_key]\n",
    "\n",
    "print(model.time_bounds)\n",
    "print(member1.get_calendar_type())  # e.g., 'noleap'\n",
    "print(member1.get_time_bounds())    # (start, end) as cftime objects\n",
    "\n",
    "print(member1.select_data('psl'))\n",
    "\n",
    "ens_mean = model.calc_ensemble_mean(Path(\"/gws/nopw/j04/extant/users/slbennie/ens_mean_spat/psl/historical/HadGEM3-GC31-LL/psl_mon_historical_HadGEM3-GC31-LL_spatial_DJF_EM_1850-2015.nc\"), 'psl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d18698c3-492d-4469-9d93-35b7fe46a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r11i1p1f3', 'r12i1p1f3', 'r13i1p1f3', 'r14i1p1f3', 'r15i1p1f3', 'r16i1p1f3', 'r17i1p1f3', 'r18i1p1f3', 'r19i1p1f3', 'r1i1p1f3', 'r20i1p1f3', 'r21i1p1f3', 'r22i1p1f3', 'r23i1p1f3', 'r24i1p1f3', 'r25i1p1f3', 'r26i1p1f3', 'r27i1p1f3', 'r28i1p1f3', 'r29i1p1f3', 'r2i1p1f3', 'r30i1p1f3', 'r31i1p1f3', 'r32i1p1f3', 'r33i1p1f3', 'r34i1p1f3', 'r35i1p1f3', 'r36i1p1f3', 'r37i1p1f3', 'r38i1p1f3', 'r39i1p1f3', 'r3i1p1f3', 'r40i1p1f3', 'r41i1p1f3', 'r42i1p1f3', 'r43i1p1f3', 'r44i1p1f3', 'r45i1p1f3', 'r46i1p1f3', 'r47i1p1f3', 'r48i1p1f3', 'r49i1p1f3', 'r4i1p1f3', 'r50i1p1f3', 'r51i1p1f3', 'r52i1p1f3', 'r53i1p1f3', 'r54i1p1f3', 'r55i1p1f3', 'r56i1p1f3', 'r57i1p1f3', 'r58i1p1f3', 'r59i1p1f3', 'r5i1p1f3', 'r60i1p1f3']\n",
      "1850\n"
     ]
    }
   ],
   "source": [
    "#idea is to create objects for all the ensembles within the folder\n",
    "#within the class there will be a method to extract the member_id from the filename\n",
    "\n",
    "\n",
    "folder = Path('/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/historical/HadGEM3-GC31-LL/')\n",
    "\n",
    "#collecting all the ensemble members in this folder - slightly tricky in that depends on this folder not really being altered?\n",
    "ensemble_members = [\n",
    "    EnsembleMemberCalculations(file)\n",
    "    for file in folder.glob(\"*.nc\")\n",
    "]\n",
    "\n",
    "print([member.member_id for member in ensemble_members])\n",
    "\n",
    "#loading in the data\n",
    "ds = ensemble_members[0].load_data()\n",
    "ensemble_members[0].get_time_bounds('1850', '2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419a3683-10fe-4331-bdfc-d9c7845ed696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<xarray.Dataset> Size: 169MB\n",
      "Dimensions:    (time: 1980, bnds: 2, lat: 71, lon: 144)\n",
      "Coordinates:\n",
      "  * time       (time) object 16kB 1850-01-16 00:00:00 ... 2014-12-16 00:00:00\n",
      "  * lat        (lat) float64 568B -87.5 -85.0 -82.5 -80.0 ... 82.5 85.0 87.5\n",
      "  * lon        (lon) float64 1kB -180.0 -177.5 -175.0 ... 172.5 175.0 177.5\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    time_bnds  (time, bnds) object 32kB ...\n",
      "    lat_bnds   (time, lat, bnds) float64 2MB ...\n",
      "    lon_bnds   (time, lon, bnds) float64 5MB ...\n",
      "    psl        (time, lat, lon) float64 162MB ...\n",
      "Attributes: (12/46)\n",
      "    Conventions:            CF-1.7 CMIP-6.2\n",
      "    activity_id:            CMIP\n",
      "    branch_method:          standard\n",
      "    branch_time_in_child:   0.0\n",
      "    branch_time_in_parent:  0.0\n",
      "    creation_date:          2019-06-19T12:06:35Z\n",
      "    ...                     ...\n",
      "    title:                  HadGEM3-GC31-LL output prepared for CMIP6\n",
      "    variable_id:            psl\n",
      "    variant_label:          r1i1p1f3\n",
      "    license:                CMIP6 model data produced by the Met Office Hadle...\n",
      "    cmor_version:           3.4.0\n",
      "    tracking_id:            hdl:21.14100/0c92cf9a-1f9c-41b3-9192-fb608624dc98\n"
     ]
    }
   ],
   "source": [
    "member1 = EnsembleMemberCalculations(\n",
    "    member_id='1',\n",
    "    data_path = Path('/gws/nopw/j04/leader_epesc/CMIP6_SinglForcHistSimul/InterpolatedFlds/psl/historical/HadGEM3-GC31-LL/psl_mon_historical_HadGEM3-GC31-LL_r1i1p1f3_interp.nc')\n",
    ")\n",
    "\n",
    "ds = member1.load_data()\n",
    "\n",
    "print(member1.member_id)\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50dee1-23dd-4ba6-ae9e-d99d49c45f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleMemberProcessing:\n",
    "    def __init__(self, member_id: str, data_path:Path):\n",
    "        #use self. to access the attributes\n",
    "        self.member_id = member_id\n",
    "        self.datat_path = Path(data_path)\n",
    "        self.data = None\n",
    "        self.eofs = None\n",
    "\n",
    "    def load_data(self):\n",
    "        #loading the LESFMIP data in for each ensemble member\n",
    "        #each object has a path attribute\n",
    "        self.data = xr.open_dataset(self.data_path)\n",
    "        return self.data\n",
    "\n",
    "    def calculate_EOF(self, domain='North Atlantic'):\n",
    "        #will add in code to calculate the EOFs\n",
    "        #for now just a test\n",
    "        #domain would be passed through.\n",
    "        print(f\"calculating the EOF for the domain: {domain} for {self.member_id\")\n",
    "        #self.eofs = xr.Dataset()\n",
    "        #EOF calculation\n",
    "        #return self.eofs\n",
    "\n",
    "    def save_eofs(self, path: Path):\n",
    "        if self.eofs is not None:\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            self.eofs.to_netcdf(path)\n",
    "            print(f\"saved EOFs for {self.member_id} to {path}\")\n",
    "\n",
    "class EnsembleMemberProcessed:\n",
    "    def __init__(self, member_id: str, eofs: xr.Dataset):\n",
    "        self.member_id = member_id\n",
    "        self.eofs = eofs\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, member_id: str, eofs_path: Path):\n",
    "        eofs = xr.open_dataset(eofs_path)\n",
    "        print(f\"Loaded EOFs for {member_id} from {eofs_path}\")\n",
    "        return cls(member_id=member_id, eofs=eofs)\n",
    "\n",
    "\n",
    "class ModelCalculations:\n",
    "    def __init__(self, model_name: str, ensemble_members_processing: dict = None, ensemble_members_processed: dict = None, eof_mode='NAO'):\n",
    "        self.model_name = model_name\n",
    "        self.eof_mode = eof_mode\n",
    "\n",
    "        #Making sue the code doesn't calculate new and load in old.\n",
    "        if ensemble_members_processing is not None and ensemble_members_processed is not None:\n",
    "            raise ValueError(\"Provide either ensemble_members_processing OR ensemble_members_processed - NOT both!\")\n",
    "\n",
    "        if ensemble_members_processing is not None:\n",
    "            self.mode = 'raw'\n",
    "            self.ensemble_members_processing = ensemble_members_processing\n",
    "            #so now it calculates the things I need, well hopefully....\n",
    "            #mid is just ensemble member id\n",
    "            #computing the EOFs\n",
    "            #results in a dictionary mapping the member ID to the processed EOFs\n",
    "            self.ensemble_members_processed = {}\n",
    "\n",
    "        elif ensemble_members_processed is not None:\n",
    "            #basically just stores the data given\n",
    "            self.mode = 'processed'\n",
    "            self.ensemble_members_processed = ensemble_members_processed\n",
    "            self.ensemble_members_processing = None\n",
    "        else:\n",
    "            raise ValueError('Need at least either ensemble_members_processing OR ensemble_members_processed')\n",
    "\n",
    "\n",
    "    # ------------------\n",
    "    # For raw members: calculate EOFs and optionally save\n",
    "    # ------------------\n",
    "    def calculate_raw_eofs(self, save_dir: Path = None):\n",
    "        if self.mode != \"raw\":\n",
    "            raise RuntimeError(\"This method is only valid for raw ensemble members.\")\n",
    "        for mid, member in self.ensemble_members_processing.items():\n",
    "            #member.load_data()\n",
    "            #eofs = member.calculate_eofs(self.eof_mode)\n",
    "            #self.ensemble_members_processing[mid] = EnsembleMemberProcessed(mid, eofs)\n",
    "            #if save_dir is not None:\n",
    "            #    save_path = save_dir / f\"{mid}_{self.eof_mode}_eofs.nc\"\n",
    "            #    member.save_eofs(save_path)\n",
    "        print(\"All raw EOFs calculated and processed members created.\")\n",
    "\n",
    "    # ------------------\n",
    "    # For processed members: load EOFs from .nc\n",
    "    # ------------------\n",
    "    @classmethod\n",
    "    def from_processed_files(cls, model_name: str, file_paths: dict, eof_mode=\"NAO\"):\n",
    "        processed_members = {}\n",
    "        for mid, path in file_paths.items():\n",
    "            processed_members[mid] = EnsembleMemberProcessed.from_file(mid, Path(path))\n",
    "        return cls(model_name, processed_ensemble_members=processed_members, eof_mode=eof_mode)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
