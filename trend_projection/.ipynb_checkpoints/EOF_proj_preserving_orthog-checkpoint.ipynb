{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56987e27-2b3f-47c3-a356-597fd34661a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cftime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import linregress\n",
    "from eofs.xarray import Eof\n",
    "from eofs.examples import example_data_path\n",
    "\n",
    "#My Functions\n",
    "import importlib\n",
    "import trend_projection_functions_new_method\n",
    "importlib.reload(trend_projection_functions_new_method)\n",
    "from trend_projection_functions_new_method import get_time_bounds\n",
    "from trend_projection_functions_new_method import get_models_for_experiment\n",
    "from trend_projection_functions_new_method import CVDP_EM_crop_NA_sector#\n",
    "from trend_projection_functions_new_method import open_cropNA_unitshPA\n",
    "from trend_projection_functions_new_method import calculate_spatial_ensemble_mean\n",
    "from trend_projection_functions_new_method import calculate_seasonal_spatial_ensemble_mean_djf\n",
    "from trend_projection_functions_new_method import calculate_linear_trend_spat_pattern\n",
    "from trend_projection_functions_new_method import calculate_regression_map\n",
    "from trend_projection_functions_new_method import project_onto_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "db252f9c-4e9d-4a60-a63b-93a7d37cb8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.7755575615628914e-17 -2.775557561562892e-17\n"
     ]
    }
   ],
   "source": [
    "def weighted_inner(EOF1, EOF2):\n",
    "    \"\"\"\n",
    "    Compute weighted inner product between two EOFs (DataArrays lat x lon)\n",
    "    \"\"\"\n",
    "    inner = (EOF1 * EOF2).sum(dim=('lat','lon'))\n",
    "    norm1 = np.sqrt((EOF1**2).sum(dim=('lat','lon')))\n",
    "    norm2 = np.sqrt((EOF2**2).sum(dim=('lat','lon')))\n",
    "    cos_sim = inner / (norm1 * norm2)\n",
    "    return float(inner), float(cos_sim)\n",
    "\n",
    "EOF_NAO = xr.open_dataset('/gws/nopw/j04/extant/users/slbennie/regression_patterns/concatenating/psl_mon_historical_HadGEM3-GC31-LL_DJF_EOF_pattern_concat_1850-20153.nc').sel(mode=0)['eofs']\n",
    "EOF_EA = xr.open_dataset('/gws/nopw/j04/extant/users/slbennie/regression_patterns/concatenating/psl_mon_historical_HadGEM3-GC31-LL_DJF_EOF_pattern_concat_1850-20153.nc').sel(mode=1)['eofs']\n",
    "\n",
    "inner, cos_sim = weighted_inner(EOF_NAO, EOF_EA)\n",
    "print(inner, cos_sim)\n",
    "\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "folder_path = f'{home}trend_calc_LESFMIP/linear_regression/NAO/historical/HadGEM3-GC31-LL/'\n",
    "ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if 'HadGEM3-GC31-LL' in filename and '1850-2015' in filename]\n",
    "trend_raw = open_cropNA_unitshPA(ens_files[0])#, 1850,2014)\n",
    "trend_raw = trend_raw * 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "60603669-228e-4497-ba2f-1226dfcc73a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Weighted inner product: -1.2996873542669984e-17 -2.7755575615628914e-17\n",
      "Weighted cosine similarity: -1.2996873542669989e-17 -2.7755575615628914e-17\n",
      "R² NAO       : 0.6018582763618643\n",
      "R² EA        : 0.13585626603985326\n",
      "R² residual  : 0.26228545759828203\n",
      "Check sum    : 0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "if isinstance(trend_raw, xr.DataArray):\n",
    "    trend = trend_raw\n",
    "else:\n",
    "    print('here')\n",
    "    trend = trend_raw['slope']\n",
    "    \n",
    "# --- Step 1: Align grids ---\n",
    "EOF_NAO_interp = EOF_NAO.interp(lat=trend['lat'], lon=trend['lon'])\n",
    "EOF_EA_interp  = EOF_EA.interp(lat=trend['lat'], lon=trend['lon'])\n",
    "\n",
    "# --- Step 2: Apply consistent mask ---\n",
    "valid_mask = np.isfinite(trend)\n",
    "trend_masked = trend.where(valid_mask).fillna(0)\n",
    "EOF_NAO_masked = EOF_NAO_interp.where(valid_mask).fillna(0)\n",
    "EOF_EA_masked  = EOF_EA_interp.where(valid_mask).fillna(0)\n",
    "\n",
    "# --- Step 3: Apply solver weights ---\n",
    "w = np.sqrt(np.cos(np.radians(trend['lat'])))\n",
    "w2d, _ = xr.broadcast(w, trend)\n",
    "Y  = (trend_masked * w2d).stack(spatial=('lat','lon')).values\n",
    "E1 = (EOF_NAO_masked).stack(spatial=('lat','lon')).values\n",
    "E2 = (EOF_EA_masked ).stack(spatial=('lat','lon')).values\n",
    "\n",
    "# --- Optional: check orthogonality ---\n",
    "inner = np.dot(E1, E2)\n",
    "cos_sim = inner / (np.linalg.norm(E1) * np.linalg.norm(E2))\n",
    "inner2, cos_sim2 = weighted_inner(EOF_NAO, EOF_EA)\n",
    "\n",
    "print(\"Weighted inner product:\", inner, inner2)\n",
    "print(\"Weighted cosine similarity:\", cos_sim, inner2)\n",
    "#there has been a slight change in EOF orthogonality when masking etc. and matching grids - could do this all prior to calc EOFS.\n",
    "\n",
    "# --- Step 4: Stack EOFs into matrix ---\n",
    "E = np.stack([E1, E2], axis=1)  # N x 2\n",
    "\n",
    "# --- Step 5: Solve weighted least squares ---\n",
    "c = np.linalg.lstsq(E, Y, rcond=None)[0]  # [c_NAO, c_EA]\n",
    "\n",
    "# --- Step 6: Reconstruct projections ---\n",
    "Y_hat_NAO = c[0] * E1\n",
    "Y_hat_EA  = c[1] * E2\n",
    "Y_hat_total = Y_hat_NAO + Y_hat_EA\n",
    "residual = Y - Y_hat_total\n",
    "\n",
    "# --- Step 7: Variance decomposition ---\n",
    "SST = np.sum(Y**2)\n",
    "R2_NAO = np.dot(Y_hat_total, Y_hat_NAO) / SST\n",
    "R2_EA  = np.dot(Y_hat_total, Y_hat_EA) / SST\n",
    "R2_res = np.sum(residual**2) / SST\n",
    "\n",
    "print(\"R² NAO       :\", R2_NAO)\n",
    "print(\"R² EA        :\", R2_EA)\n",
    "print(\"R² residual  :\", R2_res)\n",
    "print(\"Check sum    :\", R2_NAO + R2_EA + R2_res)  # should be 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "381fd718-2197-4e00-aa8c-c20987f073ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "R² NAO       : 0.6018582763618644\n",
      "R² EA        : 0.13585626603985326\n",
      "R² residual  : 0.26228545759828203\n",
      "Check sum    : 0.9999999999999997\n",
      "R² NAO       : 0.6018582763618643\n",
      "R² EA        : 0.13585626603985326\n",
      "R² residual  : 0.26228545759828203\n",
      "Check sum    : 0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "EOF_NAO = xr.open_dataset('/gws/nopw/j04/extant/users/slbennie/regression_patterns/concatenating/psl_mon_historical_HadGEM3-GC31-LL_DJF_EOF_pattern_concat_1850-20153.nc').sel(mode=0)['eofs']\n",
    "EOF_EA = xr.open_dataset('/gws/nopw/j04/extant/users/slbennie/regression_patterns/concatenating/psl_mon_historical_HadGEM3-GC31-LL_DJF_EOF_pattern_concat_1850-20153.nc').sel(mode=1)['eofs']\n",
    "\n",
    "\n",
    "home = '/gws/nopw/j04/extant/users/slbennie/'\n",
    "folder_path = f'{home}trend_calc_LESFMIP/linear_regression/NAO/historical/HadGEM3-GC31-LL/'\n",
    "ens_files = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if 'HadGEM3-GC31-LL' in filename and '1850-2015' in filename]\n",
    "trend_raw = open_cropNA_unitshPA(ens_files[0])#, 1850,2014)\n",
    "trend_raw = trend_raw * 165\n",
    "\n",
    "if isinstance(trend_raw, xr.DataArray):\n",
    "    trend = trend_raw\n",
    "else:\n",
    "    print('here')\n",
    "    trend = trend_raw['slope']\n",
    "    \n",
    "# --- Solver weight ---\n",
    "w = np.sqrt(np.cos(np.radians(trend['lat'])))\n",
    "w2d, _ = xr.broadcast(w, trend)  # shape lat x lon\n",
    "\n",
    "# --- Apply consistent mask: NaNs in trend are masked in EOFs ---\n",
    "valid = np.isfinite(trend)\n",
    "trend_masked = trend.where(valid).fillna(0)\n",
    "EOF_NAO_masked = EOF_NAO.where(valid).fillna(0)\n",
    "EOF_EA_masked  = EOF_EA.where(valid).fillna(0)\n",
    "\n",
    "# --- Flatten and apply weights ---\n",
    "Y  = (trend_masked * w2d).stack(spatial=('lat','lon')).values\n",
    "E1 = (EOF_NAO_masked).stack(spatial=('lat','lon')).values\n",
    "E2 = (EOF_EA_masked).stack(spatial=('lat','lon')).values\n",
    "E  = np.stack([E1, E2], axis=1)  # N x 2\n",
    "\n",
    "# --- Solve weighted least squares ---\n",
    "c = np.linalg.lstsq(E, Y, rcond=None)[0]  # coefficients: [c_NAO, c_EA]\n",
    "#basically it finds the coefficients that best approximate the trend field Y\n",
    "#as a linear combination of the EOFS I have given it.\n",
    "\n",
    "\n",
    "# --- Reconstruct and residual ---\n",
    "#this basically reconstructs the field from the basis (EOFs -E) and their coefficients (c)\n",
    "# basically: Y^=c0*E1+c1*E2\n",
    "Y_hat = E @ c\n",
    "residual = Y - Y_hat\n",
    "\n",
    "# --- Variance decomposition ---\n",
    "#SST = np.sum(Y**2)\n",
    "#R2_NAO = c[0]**2 * np.sum(E1**2) / SST\n",
    "#R2_EA  = c[1]**2 * np.sum(E2**2) / SST\n",
    "#R2_res = np.sum(residual**2) / SST\n",
    "\n",
    "Y_hat_NAO = c[0] * E1\n",
    "Y_hat_EA  = c[1] * E2\n",
    "residual  = Y - Y_hat_NAO - Y_hat_EA\n",
    "\n",
    "SST = np.sum(Y**2)\n",
    "R2_NAO = np.sum(Y_hat_NAO**2) / SST\n",
    "R2_EA  = np.sum(Y_hat_EA**2) / SST\n",
    "R2_res = np.sum(residual**2) / SST\n",
    "\n",
    "\n",
    "print(\"R² NAO       :\", R2_NAO)\n",
    "print(\"R² EA        :\", R2_EA)\n",
    "print(\"R² residual  :\", R2_res)\n",
    "print(\"Check sum    :\", R2_NAO + R2_EA + R2_res)  # should be 1\n",
    "\n",
    "\n",
    "# Full reconstructed field\n",
    "Y_hat_total = Y_hat_NAO + Y_hat_EA\n",
    "\n",
    "# Residual\n",
    "residual = Y - Y_hat_total\n",
    "\n",
    "# Total variance\n",
    "SST = np.sum(Y**2)\n",
    "\n",
    "# Fraction of variance explained\n",
    "R2_total = 1 - np.sum(residual**2) / SST\n",
    "\n",
    "# Incremental contributions (optional)\n",
    "# Use projection of Y_hat_total onto each mode in the weighted inner product space\n",
    "R2_NAO = np.dot(Y_hat_total, Y_hat_NAO) / SST\n",
    "R2_EA  = np.dot(Y_hat_total, Y_hat_EA) / SST\n",
    "R2_res = np.sum(residual**2) / SST\n",
    "\n",
    "print(\"R² NAO       :\", R2_NAO)\n",
    "print(\"R² EA        :\", R2_EA)\n",
    "print(\"R² residual  :\", R2_res)\n",
    "print(\"Check sum    :\", R2_NAO + R2_EA + R2_res)  # should be 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6a6db-eded-4906-886e-0133aaaf07a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
