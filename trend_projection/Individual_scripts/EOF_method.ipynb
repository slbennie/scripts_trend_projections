{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfcb0b7-096c-4373-9bec-417a304cc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from eofs.xarray import Eof\n",
    "\n",
    "\n",
    "def calc_EOF_per_ensemble(self,max_modes: int):\n",
    "    \"\"\"\n",
    "    Want to calculate the EOF for each ensmeble member per model per experiment (for projection just historical EOF NOT SF!!)\n",
    "    Will do this by literally just using the psl_anomalies (in Pa) and then calling the seasonal mean method\n",
    "    Will also check whether this data already exists or not and load if it does\n",
    "    Bear in mind - the time coordinate is YEAR after seasonal means so need to change back to TIME\n",
    "    EOF0 = EOF unitless, pc in hPa (equiv to pcscaling=0)\n",
    "    EOF1 = the normalised EOF where EOF in hPa, PCs are unitless and (pc/sqrt(eigenvals)) and (EOF*sqrt(eigenvals))  (equiv to pcscaling=1)\n",
    "    Finds the EOFs for the number of modes specified\n",
    "    \"\"\"\n",
    "    output_file_EOF = self.all_experiments.output_dir / f\"EOF/{self.experiment.name}/{self.all_experiments.season_str}/normalised_aligned/{self.model.name}/psl_mon_{self.experiment.name}_{self.model.name}_{self.member_id}_{self.all_experiments.season_str}_EOF_indiv_{self.model.time_bounds[3]}.nc\"\n",
    "\n",
    "    #if the EOF already exists then just load that in\n",
    "    if output_file_EOF.exists():\n",
    "        print(f\"Loading the EOF for ensemble member {self.member_id} in model {self.model.name} and {self.experiment.name}\")\n",
    "        return xr.open_dataset(output_file_EOF)\n",
    "\n",
    "    #calulate the EOF, PC and regression map from seasonal anomalies and convert to hPa\n",
    "    print('calculating the EOF')\n",
    "    anomaly = self.calc_seas_anomaly().rename({'year': 'time'}) / 100\n",
    "\n",
    "    #transpose the anomalies\n",
    "    anomaly_trans = anomaly.transpose('time', 'lat', 'lon')\n",
    "\n",
    "    #calculating the weights sqrt(cos(lat))\n",
    "    coslat = np.cos(np.deg2rad(anomaly_trans.coords['lat'].values)).clip(0., 1.)\n",
    "    wgts = np.sqrt(coslat)[...,np.newaxis]\n",
    "\n",
    "    #making the solver from the Eof package\n",
    "    solver = Eof(anomaly_trans, weights=wgts)\n",
    "\n",
    "    #calculating EOF0 and EOF1 and the eigenvalues\n",
    "    EOF0 = solver.eofs(neofs=max_modes)\n",
    "    eigs = solver.eigenvalues(neigs=max_modes)\n",
    "    EOF1 = EOF0 * np.sqrt(eigs.values)[:, np.newaxis, np.newaxis]\n",
    "\n",
    "    #calculating the PCs and the variance explained by the PC\n",
    "    PCs = solver.pcs(npcs=max_modes, pcscaling=1).transpose('mode', 'time')\n",
    "    var_frac = solver.varianceFraction(neigs=max_modes)\n",
    "\n",
    "    #could also find the regression map (first demean time)\n",
    "    #Basically converting the PCs back into a map with units of hPa/unit PC\n",
    "    anomaly_trans_demeaned = anomaly_trans - anomaly_trans.mean(dim='time')\n",
    "    PCs_demeaned = PCs - PCs.mean(dim='time')\n",
    "\n",
    "    reg_maps = []\n",
    "\n",
    "    #for each leading mode calc the reg maps\n",
    "    for n in range(max_modes):\n",
    "        cov = (anomaly_trans_demeaned * PCs_demeaned.isel(mode=n)).mean(dim='time') * wgts\n",
    "        var = (PCs_demeaned.isel(mode=n)**2).mean(dim='time')\n",
    "        reg_map = cov / var\n",
    "        reg_map = reg_map.expand_dims(mode=[n])\n",
    "        reg_maps.append(reg_map)\n",
    "\n",
    "    regressions = xr.concat(reg_maps, dim='mode')\n",
    "    regressions.name = 'regressions'\n",
    "    #regression_map = (anomaly_trans * PC_demeaned).mean(dim='time')*wgts\n",
    "\n",
    "    #Putting it all in one dataset - I only will use EOF1 from now on? hopefully?...\n",
    "    ds = xr.Dataset({\n",
    "        'eofs' : EOF1,\n",
    "        'PCs' : PCs,\n",
    "        'regressions' : regressions,\n",
    "        #'var_frac' : (['mode'], var_frac)\n",
    "    })\n",
    "\n",
    "    #some metadata\n",
    "    ds.attrs.update({\n",
    "        'model': self.model.name,\n",
    "        'experiment': self.experiment.name,\n",
    "        'member_id' : self.member_id,\n",
    "        'description': ('EOF, PC, and regression map per ensemble member.\\n'\n",
    "                       'EOFs are scaled by sqrt(eigenvalue) so that PCs are unitless and EOFs are in hPa')\n",
    "    })\n",
    "\n",
    "    ds.to_netcdf(output_file_EOF)\n",
    "    print(f'The fraction of variance explained in model {self.model.name} and member {self.member_id}: {var_frac}')\n",
    "\n",
    "    print(ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbc272-292a-40d1-b295-41e8fe1b56ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
